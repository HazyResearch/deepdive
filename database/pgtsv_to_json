#!/usr/bin/env python
# A script to convert PostgreSQL's COPY TO text (tsv; tab-delimited values) lines into JSON sequence
# Usage: pgtsv_to_json COLUMN_NAME1:TYPE1 COLUMN_NAME2:TYPE2 ...

import json, sys, csv, re, codecs
from datetime import datetime


ESCAPE_SEQUENCE_RE = re.compile(r'''
    ( \\U........      # 8-digit hex escapes
    | \\u....          # 4-digit hex escapes
    | \\x..            # 2-digit hex escapes
    | \\[0-7]{1,3}     # Octal escapes
    | \\N\{[^}]+\}     # Unicode characters by name
    | \\[\\'"abfnrtv]  # Single-character escapes
    )''', re.UNICODE | re.VERBOSE)

def decode_python_escapes(s):
  '''Decode characters matching Python escape sequences in the given UTF-8 string,
  but leave all actual unicode alone.

  Use this instead of unicode.decode('unicode_escape'). See http://stackoverflow.com/a/24519338/465511
  '''
  def decode_match(match):
    return codecs.decode(match.group(0), 'unicode-escape')
  return ESCAPE_SEQUENCE_RE.sub(decode_match, s)

def timestamp(timestamp_str):
    """Given a timestamp string, return a timestamp string in ISO 8601 format to emulate
    Postgres 9.5's to_json timestamp formatting.

    This supports the `timestamp without time zone` PostgreSQL type.

    Time zone offsets are not supported. http://bugs.python.org/issue6641

    Examples:

        >>> timestamp('2016-06-17 20:10:38')
        '2016-06-17T20:10:38'

        >>> timestamp('2016-06-17 20:10:37.9293')
        '2016-06-17T20:10:37.929300'

    """

    try:
        parsed = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S.%f')
    except ValueError:
        parsed = datetime.strptime(timestamp_str, '%Y-%m-%d %H:%M:%S')
    except ValueError:
        return timestamp_str
    return parsed.isoformat()

# given a column type, returns a function that takes a string input
# and output with the correct type
def convert_type_func(ty, ty_rest = ""):
  if ty.endswith("[]") and ty_rest == "": # XXX nested arrays are not supported
    # csv array starts and ends with curly braces
    ty_el = ty[:-2]
    convert = convert_type_func(ty_el, ty_rest=ty[-2:])
    def backslashes_to_csv_escapes(s):
        return re.sub(r"\\(.)", lambda m: '""' if m.group(1) is '"' else m.group(1), s)
    if ty_el == "text":
      def convert_text_array(value):
        arr = unicode_csv_reader([backslashes_to_csv_escapes(value[1:-1])], delimiter=',', quotechar='"', escapechar='\\').next()
        return map(convert, arr)
      return convert_text_array
    else:
      def convert_other_array(value):
        arr = unicode_csv_reader([value[1:-1]], delimiter=',', quotechar='"').next()
        return map(convert, arr)
      return convert_other_array
  else: # non-array, must be primitive type
    normalized_type_name = {
        "timestamp without time zone": "timestamp",
        "integer" : "int",
        "bigint"  : "int",
        "double"  : "float",
        "numeric" : "float",
        "unknown" : "text",
        }
    convert_for_primitive_types = {
        "timestamp": timestamp,
        "int"     : int,
        "float"   : float,
        "text"    : lambda x: unescape_postgres_text_format(decode_python_escapes(x)),
        "boolean" : lambda x: x == "t",
        }
    # find the convert function with normalized type name
    ty = ty.lower()
    if re.match('timestamp(\(\d\))? without time zone', ty):
      ty = 'timestamp without time zone'
    if ty in normalized_type_name:
      ty = normalized_type_name[ty]
    if ty in convert_for_primitive_types:
      return convert_for_primitive_types[ty]
    else:
      raise ValueError("Unsupported data type %s" % ty)

# PostgreSQL COPY TO text Format parser
# See: http://www.postgresql.org/docs/9.1/static/sql-copy.html#AEN64302
pgTextEscapeSeqs = {
    "b": "\b",
    "f": "\f",
    "n": "\n",
    "r": "\r",
    "t": "\t",
    "v": "\v",
    }

def decode_pg_text_escapes(m):
  c = m.group(1)
  if c in pgTextEscapeSeqs:
    return pgTextEscapeSeqs[c]
  else:
    return c

def unescape_postgres_text_format(s):
  # unescape PostgreSQL text format
  return re.sub(r"\\(.|0[0-7]{1,2}|x[0-9A-Fa-f]{1,2})", decode_pg_text_escapes, s)

def utf_8_encoder(unicode_csv_data):
    for line in unicode_csv_data:
        yield line.encode('utf-8')


def unicode_csv_reader(unicode_csv_data, **kwargs):
    '''A generator for unicode lines from a csv file.

    This function takes all the same parameters as `csv.reader`. It was copied
    directly from the documentation for that module:

    https://docs.python.org/2/library/csv.html#examples

    '''
    # csv.py doesn't do Unicode; encode temporarily as UTF-8:
    csv_reader = csv.reader(utf_8_encoder(unicode_csv_data), **kwargs)
    for row in csv_reader:
        # decode UTF-8 back to Unicode, cell by cell:
        yield [unicode(cell, 'utf-8') for cell in row]

def main():
  # parse column names and types from arguments
  def parseArg(arg):
      field_name, field_type = re.match(r"(.+):([^:]+)", arg).groups()
      return field_name, convert_type_func(field_type)
  names_converters = map(parseArg, sys.argv[1:])

  # read the PostgreSQL COPY TO text format
  # XXX With Python's csv.reader, it's impossible to distinguish empty strings from nulls in PostgreSQL's csv output.
  # In PostgreSQL's csv output, `1,,2.34` means 1, null, 2.34, whereas `1,"",2.34` means 1, empty string, 2.34.
  # csv.reader provides no formatter option to handle this.
  # See: http://grokbase.com/t/python/python-ideas/131b0eaykx/csv-dialect-enhancement
  # See: http://stackoverflow.com/questions/11379300/python-csv-reader-behavior-with-none-and-empty-string
  # See: https://github.com/JoshClose/CsvHelper/issues/252
  utf8_reader = codecs.getreader('utf8')
  reader = unicode_csv_reader(utf8_reader(sys.stdin), delimiter='\t', quotechar=None, quoting=csv.QUOTE_NONE)
  for line in reader:
    obj = {}
    for (name, convert), field in zip(names_converters, line):
        obj[name] = None if field == "\\N" \
                         else convert(field)
    print json.dumps(obj, ensure_ascii=False).encode('utf-8')

if __name__ == "__main__":
  main()

