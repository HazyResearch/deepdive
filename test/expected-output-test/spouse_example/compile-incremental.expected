
  deepdive.db.default {
    driver: "org.postgresql.Driver"
    url: "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME}
    user: ${PGUSER}
    password: ${PGPASSWORD}
    dbname: ${DBNAME}
    host: ${PGHOST}
    port: ${PGPORT}
    incremental_mode: INCREMENTAL
    }
    

      deepdive.schema.keys {
        dd_delta_has_spouse : [relation_id]
        dd_new_has_spouse : [relation_id]
      }

      deepdive.schema.variables {
        has_spouse.label: Boolean
dd_delta_has_spouse.label: Boolean
dd_new_has_spouse.label: Boolean
      }
    

          deepdive.extraction.extractors.init_dd_delta_articles {
            sql: """ DROP TABLE IF EXISTS dd_delta_articles CASCADE;
            CREATE TABLE
            dd_delta_articles(article_id text,
                 text text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_new_people_mentions {
            sql: """ DROP TABLE IF EXISTS dd_new_people_mentions CASCADE;
            CREATE TABLE
            dd_new_people_mentions(sentence_id text,
                      start_position int,
                      length int,
                      text text,
                      mention_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_delta_has_spouse_features {
            sql: """ DROP TABLE IF EXISTS dd_delta_has_spouse_features CASCADE;
            CREATE TABLE
            dd_delta_has_spouse_features(relation_id text,
                            feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_new_articles {
            sql: """ DROP TABLE IF EXISTS dd_new_articles CASCADE;
            CREATE TABLE
            dd_new_articles(article_id text,
               text text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_new_has_spouse_candidates {
            sql: """ DROP TABLE IF EXISTS dd_new_has_spouse_candidates CASCADE;
            CREATE TABLE
            dd_new_has_spouse_candidates(person1_id text,
                            person2_id text,
                            sentence_id text,
                            description text,
                            relation_id text,
                            is_true boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_new_has_spouse_features {
            sql: """ DROP TABLE IF EXISTS dd_new_has_spouse_features CASCADE;
            CREATE TABLE
            dd_new_has_spouse_features(relation_id text,
                          feature text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_new_sentences {
            sql: """ DROP TABLE IF EXISTS dd_new_sentences CASCADE;
            CREATE TABLE
            dd_new_sentences(document_id text,
                sentence text,
                words text[],
                lemma text[],
                pos_tags text[],
                dependencies text[],
                ner_tags text[],
                sentence_offset int,
                sentence_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_delta_people_mentions {
            sql: """ DROP TABLE IF EXISTS dd_delta_people_mentions CASCADE;
            CREATE TABLE
            dd_delta_people_mentions(sentence_id text,
                        start_position int,
                        length int,
                        text text,
                        mention_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_delta_has_spouse_candidates {
            sql: """ DROP TABLE IF EXISTS dd_delta_has_spouse_candidates CASCADE;
            CREATE TABLE
            dd_delta_has_spouse_candidates(person1_id text,
                              person2_id text,
                              sentence_id text,
                              description text,
                              relation_id text,
                              is_true boolean)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_delta_sentences {
            sql: """ DROP TABLE IF EXISTS dd_delta_sentences CASCADE;
            CREATE TABLE
            dd_delta_sentences(document_id text,
                  sentence text,
                  words text[],
                  lemma text[],
                  pos_tags text[],
                  dependencies text[],
                  ner_tags text[],
                  sentence_offset int,
                  sentence_id text)
            """
            style: "sql_extractor"
          }

          deepdive.extraction.extractors.init_dd_delta_has_spouse {
            sql: """ DROP TABLE IF EXISTS dd_delta_has_spouse CASCADE;
            CREATE TABLE
            dd_delta_has_spouse(relation_id text,
                   id bigint,
                   label boolean)
            """
            style: "sql_extractor"
          }

        deepdive.extraction.extractors.cleanup {
          sql: """
          TRUNCATE dd_delta_articles;
          TRUNCATE dd_new_people_mentions;
          TRUNCATE dd_delta_has_spouse_features;
          TRUNCATE dd_new_articles;
          TRUNCATE dd_new_has_spouse_candidates;
          TRUNCATE dd_new_has_spouse_features;
          TRUNCATE dd_new_sentences;
          TRUNCATE dd_delta_people_mentions;
          TRUNCATE dd_delta_has_spouse_candidates;
          TRUNCATE dd_delta_sentences;
          TRUNCATE dd_delta_has_spouse;
          """
          style: "sql_extractor"
        }

      deepdive.extraction.extractors.ext_dd_new_people_mentions {
        cmd: """

	# TODO use temporary table
	deepdive create table "dd_new_people_mentions"
	deepdive sql 'INSERT INTO dd_new_people_mentions SELECT R0.sentence_id, R0.start_position, R0.length, R0.text, R0.mention_id
FROM people_mentions R0
        
UNION ALL
SELECT R0.sentence_id, R0.start_position, R0.length, R0.text, R0.mention_id
FROM dd_delta_people_mentions R0
        '
	# TODO rename temporary table to replace output_relation
	
        """
          output_relation: "dd_new_people_mentions"
        style: "cmd_extractor"
          dependencies: [ "ext_dd_delta_people_mentions_by_ext_people" ]
          input_relations: [
            people_mentions
            dd_delta_people_mentions
          ]
      }
    

      deepdive.extraction.extractors.ext_dd_new_articles {
        cmd: """

	# TODO use temporary table
	deepdive create table "dd_new_articles"
	deepdive sql 'INSERT INTO dd_new_articles SELECT R0.article_id, R0.text
FROM articles R0
        
UNION ALL
SELECT R0.article_id, R0.text
FROM dd_delta_articles R0
        '
	# TODO rename temporary table to replace output_relation
	
        """
          output_relation: "dd_new_articles"
        style: "cmd_extractor"
          
          input_relations: [
            articles
            dd_delta_articles
          ]
      }
    

      deepdive.extraction.extractors.ext_dd_new_has_spouse_candidates {
        cmd: """

	# TODO use temporary table
	deepdive create table "dd_new_has_spouse_candidates"
	deepdive sql 'INSERT INTO dd_new_has_spouse_candidates SELECT R0.person1_id, R0.person2_id, R0.sentence_id, R0.description, R0.relation_id, R0.is_true
FROM has_spouse_candidates R0
        
UNION ALL
SELECT R0.person1_id, R0.person2_id, R0.sentence_id, R0.description, R0.relation_id, R0.is_true
FROM dd_delta_has_spouse_candidates R0
        '
	# TODO rename temporary table to replace output_relation
	
        """
          output_relation: "dd_new_has_spouse_candidates"
        style: "cmd_extractor"
          dependencies: [ "ext_dd_delta_has_spouse_candidates_by_ext_has_spouse" ]
          input_relations: [
            has_spouse_candidates
            dd_delta_has_spouse_candidates
          ]
      }
    

      deepdive.extraction.extractors.ext_dd_new_has_spouse_features {
        cmd: """

	# TODO use temporary table
	deepdive create table "dd_new_has_spouse_features"
	deepdive sql 'INSERT INTO dd_new_has_spouse_features SELECT R0.relation_id, R0.feature
FROM has_spouse_features R0
        
UNION ALL
SELECT R0.relation_id, R0.feature
FROM dd_delta_has_spouse_features R0
        '
	# TODO rename temporary table to replace output_relation
	
        """
          output_relation: "dd_new_has_spouse_features"
        style: "cmd_extractor"
          dependencies: [ "ext_dd_delta_has_spouse_features_by_ext_has_spouse_features" ]
          input_relations: [
            has_spouse_features
            dd_delta_has_spouse_features
          ]
      }
    

      deepdive.extraction.extractors.ext_dd_new_sentences {
        cmd: """

	# TODO use temporary table
	deepdive create table "dd_new_sentences"
	deepdive sql 'INSERT INTO dd_new_sentences SELECT R0.document_id, R0.sentence, R0.words, R0.lemma, R0.pos_tags, R0.dependencies, R0.ner_tags, R0.sentence_offset, R0.sentence_id
FROM sentences R0
        
UNION ALL
SELECT R0.document_id, R0.sentence, R0.words, R0.lemma, R0.pos_tags, R0.dependencies, R0.ner_tags, R0.sentence_offset, R0.sentence_id
FROM dd_delta_sentences R0
        '
	# TODO rename temporary table to replace output_relation
	
        """
          output_relation: "dd_new_sentences"
        style: "cmd_extractor"
          
          input_relations: [
            sentences
            dd_delta_sentences
          ]
      }
    

      deepdive.extraction.extractors.ext_dd_delta_has_spouse {
        cmd: """

	# TODO use temporary table
	deepdive create table "dd_delta_has_spouse"
	deepdive sql 'INSERT INTO dd_delta_has_spouse SELECT DISTINCT R0.relation_id, 0 AS id, R0.is_true AS label
          FROM dd_delta_has_spouse_candidates R0
        
          '
	# TODO rename temporary table to replace output_relation
	
        """
          output_relation: "dd_delta_has_spouse"
        style: "cmd_extractor"
          dependencies: [ "ext_dd_delta_has_spouse_candidates_by_ext_has_spouse" ]
          input_relations: [
            dd_delta_has_spouse_candidates
          ]
      }
    

      deepdive.extraction.extractors.ext_dd_new_has_spouse {
        cmd: """

	deepdive create view dd_new_has_spouse as 'SELECT DISTINCT R0.relation_id, id, label
          FROM has_spouse R0
        
          
UNION ALL
SELECT DISTINCT R0.relation_id, id, label
          FROM dd_delta_has_spouse R0
        
          '
	
        """
          output_relation: "dd_new_has_spouse"
        style: "cmd_extractor"
          dependencies: [ "ext_dd_delta_has_spouse" ]
          input_relations: [
            has_spouse
            dd_delta_has_spouse
          ]
      }
    

        deepdive.extraction.extractors.ext_dd_delta_people_mentions_by_ext_people {
          input: """ SELECT R0.sentence_id AS "dd_delta_sentences.R0.sentence_id", ARRAY_TO_STRING(R0.words, '~^~') AS column_1, ARRAY_TO_STRING(R0.ner_tags, '~^~') AS column_2
FROM dd_delta_sentences R0
        
          """
          output_relation: "dd_delta_people_mentions"
          udf: ${APP_HOME}"/udf/ext_people.py"
          style: "tsv_extractor" 
          
          input_relations: [
            dd_delta_sentences
          ]
          input_batch_size: ${INPUT_BATCH_SIZE}
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.ext_dd_delta_has_spouse_candidates_by_ext_has_spouse {
          input: """ SELECT R0.sentence_id AS "dd_delta_people_mentions.R0.sentence_id", R0.mention_id AS "dd_delta_people_mentions.R0.mention_id", R0.text AS "dd_delta_people_mentions.R0.text", R1.mention_id AS "people_mentions.R1.mention_id", R1.text AS "people_mentions.R1.text"
FROM dd_delta_people_mentions R0, people_mentions R1
        WHERE R1.sentence_id = R0.sentence_id 
UNION ALL
SELECT R0.sentence_id AS "dd_delta_people_mentions.R0.sentence_id", R0.mention_id AS "dd_delta_people_mentions.R0.mention_id", R0.text AS "dd_delta_people_mentions.R0.text", R1.mention_id AS "people_mentions.R1.mention_id", R1.text AS "people_mentions.R1.text"
FROM dd_new_people_mentions R0, dd_delta_people_mentions R1
        WHERE R1.sentence_id = R0.sentence_id 
          """
          output_relation: "dd_delta_has_spouse_candidates"
          udf: ${APP_HOME}"/udf/ext_has_spouse.py"
          style: "tsv_extractor" 
          dependencies: [ "ext_dd_delta_people_mentions_by_ext_people" ,  "ext_dd_new_people_mentions" ]
          input_relations: [
            dd_delta_people_mentions
            people_mentions
            dd_new_people_mentions
          ]
          input_batch_size: ${INPUT_BATCH_SIZE}
          parallelism: ${PARALLELISM}
        }
      

        deepdive.extraction.extractors.ext_dd_delta_has_spouse_features_by_ext_has_spouse_features {
          input: """ SELECT ARRAY_TO_STRING(R0.words, '~^~') AS column_0, R1.relation_id AS "has_spouse_candidates.R1.relation_id", R2.start_position AS "people_mentions.R2.start_position", R2.length AS "people_mentions.R2.length", R3.start_position AS "people_mentions.R3.start_position", R3.length AS "people_mentions.R3.length"
FROM dd_delta_sentences R0, has_spouse_candidates R1, people_mentions R2, people_mentions R3
        WHERE R1.sentence_id = R0.sentence_id  AND R2.sentence_id = R0.sentence_id  AND R2.mention_id = R1.person1_id  AND R3.sentence_id = R0.sentence_id  AND R3.mention_id = R1.person2_id 
UNION ALL
SELECT ARRAY_TO_STRING(R0.words, '~^~') AS column_0, R1.relation_id AS "has_spouse_candidates.R1.relation_id", R2.start_position AS "people_mentions.R2.start_position", R2.length AS "people_mentions.R2.length", R3.start_position AS "people_mentions.R3.start_position", R3.length AS "people_mentions.R3.length"
FROM dd_new_sentences R0, dd_delta_has_spouse_candidates R1, people_mentions R2, people_mentions R3
        WHERE R1.sentence_id = R0.sentence_id  AND R2.sentence_id = R0.sentence_id  AND R2.mention_id = R1.person1_id  AND R3.sentence_id = R0.sentence_id  AND R3.mention_id = R1.person2_id 
UNION ALL
SELECT ARRAY_TO_STRING(R0.words, '~^~') AS column_0, R1.relation_id AS "has_spouse_candidates.R1.relation_id", R2.start_position AS "people_mentions.R2.start_position", R2.length AS "people_mentions.R2.length", R3.start_position AS "people_mentions.R3.start_position", R3.length AS "people_mentions.R3.length"
FROM dd_new_sentences R0, dd_new_has_spouse_candidates R1, dd_delta_people_mentions R2, people_mentions R3
        WHERE R1.sentence_id = R0.sentence_id  AND R2.sentence_id = R0.sentence_id  AND R2.mention_id = R1.person1_id  AND R3.sentence_id = R0.sentence_id  AND R3.mention_id = R1.person2_id 
UNION ALL
SELECT ARRAY_TO_STRING(R0.words, '~^~') AS column_0, R1.relation_id AS "has_spouse_candidates.R1.relation_id", R2.start_position AS "people_mentions.R2.start_position", R2.length AS "people_mentions.R2.length", R3.start_position AS "people_mentions.R3.start_position", R3.length AS "people_mentions.R3.length"
FROM dd_new_sentences R0, dd_new_has_spouse_candidates R1, dd_new_people_mentions R2, dd_delta_people_mentions R3
        WHERE R1.sentence_id = R0.sentence_id  AND R2.sentence_id = R0.sentence_id  AND R2.mention_id = R1.person1_id  AND R3.sentence_id = R0.sentence_id  AND R3.mention_id = R1.person2_id 
          """
          output_relation: "dd_delta_has_spouse_features"
          udf: ${APP_HOME}"/udf/ext_has_spouse_features.py"
          style: "tsv_extractor" 
          dependencies: [ "ext_dd_delta_has_spouse_candidates_by_ext_has_spouse" ,  "ext_dd_new_sentences" ,  "ext_dd_delta_people_mentions_by_ext_people" ,  "ext_dd_new_people_mentions" ,  "ext_dd_new_has_spouse_candidates" ]
          input_relations: [
            dd_delta_sentences
            has_spouse_candidates
            people_mentions
            dd_new_sentences
            dd_delta_has_spouse_candidates
            dd_new_has_spouse_candidates
            dd_delta_people_mentions
            dd_new_people_mentions
          ]
          input_batch_size: ${INPUT_BATCH_SIZE}
          parallelism: ${PARALLELISM}
        }
      

        deepdive.inference.factors.dd_delta_inf_istrue_has_spouse {
          input_query: """
          SELECT R0.id AS "dd_new_has_spouse.R0.id" , R2.feature AS "dd_weight_column_0" 
          FROM dd_new_has_spouse R0, dd_delta_has_spouse_candidates R1, has_spouse_features R2
        WHERE R1.relation_id = R0.relation_id  AND R2.relation_id = R0.relation_id  UNION ALL 
          SELECT R0.id AS "dd_new_has_spouse.R0.id" , R2.feature AS "dd_weight_column_0" 
          FROM dd_new_has_spouse R0, dd_new_has_spouse_candidates R1, dd_delta_has_spouse_features R2
        WHERE R1.relation_id = R0.relation_id  AND R2.relation_id = R0.relation_id """
          function: "Imply(dd_new_has_spouse.R0.label)"
          weight: "?(dd_weight_column_0)"
          dependencies: [ "ext_dd_delta_has_spouse_candidates_by_ext_has_spouse" ,  "ext_dd_new_has_spouse_candidates" ,  "ext_dd_delta_has_spouse_features_by_ext_has_spouse_features" ]
          input_relations: [
            dd_new_has_spouse
            dd_delta_has_spouse_candidates
            has_spouse_features
            dd_new_has_spouse_candidates
            dd_delta_has_spouse_features
          ]
        }
      
deepdive.pipeline.run: ${PIPELINE}
deepdive.pipeline.pipelines.extraction: [
  ext_dd_new_has_spouse_candidates
  ext_dd_delta_has_spouse_candidates_by_ext_has_spouse
  ext_dd_new_has_spouse
  ext_dd_delta_has_spouse
  ext_dd_delta_has_spouse_features_by_ext_has_spouse_features
  ext_dd_new_has_spouse_features
  ext_dd_delta_people_mentions_by_ext_people
  ext_dd_new_people_mentions
  ext_dd_new_sentences
  ext_dd_new_articles
]
deepdive.pipeline.pipelines.inference: [
  dd_delta_inf_istrue_has_spouse
]
deepdive.pipeline.pipelines.endtoend: [
  ext_dd_new_has_spouse_candidates
  ext_dd_delta_has_spouse_candidates_by_ext_has_spouse
  ext_dd_new_has_spouse
  ext_dd_delta_has_spouse
  ext_dd_delta_has_spouse_features_by_ext_has_spouse_features
  ext_dd_new_has_spouse_features
  ext_dd_delta_people_mentions_by_ext_people
  ext_dd_new_people_mentions
  ext_dd_new_sentences
  ext_dd_new_articles
  dd_delta_inf_istrue_has_spouse
]
deepdive.pipeline.base_dir: ${BASEDIR}
deepdive.pipeline.pipelines.initdb: [
  init_dd_delta_articles
  init_dd_new_people_mentions
  init_dd_delta_has_spouse_features
  init_dd_new_articles
  init_dd_new_has_spouse_candidates
  init_dd_new_has_spouse_features
  init_dd_new_sentences
  init_dd_delta_people_mentions
  init_dd_delta_has_spouse_candidates
  init_dd_delta_sentences
  init_dd_delta_has_spouse
  init_dd_new_has_spouse
]
deepdive.pipeline.pipelines.cleanup: [
  cleanup
]
