#!/usr/bin/env jq
# compile-config-2.01-grounding -- Adds processes for grounding the factor graph
##

include "constants";
include "util";
include "sql";

# skip adding grounding processes unless there are variables and factors defined
if (.deepdive_.schema.variables_  | length) == 0
or (.deepdive_.inference.factors_ | length) == 0
then . else

def factorWeightDescriptionSqlExpr:
    [ ("\(.factorName)-" | asSqlLiteral)
    , (.weight_.params[] |
        "CASE WHEN \(asSqlIdent) IS NULL THEN ''
              ELSE \(asSqlIdent) || ''  -- XXX CAST(... AS TEXT) unsupported by MySQL
          END"
      )
    ] | join(" ||\("-" | asSqlLiteral)|| ")
    ;

# generate a SQL CTE for redefining user's variable table names to have id columns with joins
# necessary for .deepdive.inference.factors.*.input_query as well as .deepdive.calibration.holdout_query
def withRedefinitionsWithJoinsForIdColumns:
    if length > 0 then "WITH \(
        [ .[]
        | "\(.variablesTable | asSqlIdent) AS (\n\(
            { SELECT:
                [ ( .variablesKeyColumns[], deepdiveVariableIdColumn
                | { alias: ., table: "i", column: . } )
                # XXX add these back on demand for the cases where inference rule uses them
                #, ( .variablesCategoryColumns[]
                #| { alias: ., table: "v", column: . } )
                ]
            , FROM: { alias: "i", table: .variablesIdsTable }
            #, JOIN:
            #    [ { LEFT_OUTER: { alias: "v", table: .variablesTable  }
            #      , ON: { and: [ .variablesKeyColumns[]
            #                   | { eq: [ { table: "v", column: . }
            #                           , { table: "i", column: . } ]
            #                     } ] }
            #      } ]
            } | asSql)\n)"
        ] | join("\n   , "))" | "\n\(.)\n----\n"
    else "" end
    ;

.deepdive_ as $deepdive

###############################################################################

## variable/*/materialize
# Each internal variable table holding distinct variables should be
# materialized first for correct id assignment, etc.
| .deepdive_.execution.processes += merge($deepdive.schema.variables_[] | {
    "process/grounding/variable/\(.variableName)/materialize": {
        dependencies_: [
            "process/grounding/from_grounding",
            "data/\(.variablesTable)"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        \(if .variableType == "categorical" then "
        # generate a table holding all distinct categories for categorical variables
        # so a unique id can be assigned to each of them
        deepdive create table \(.variablesCategoriesTable | @sh) as \(
        { SELECT:
            [ (.variablesCategoryColumns[]
            | { alias: "_\(.)", table: "v", column: . })
            , { alias: "count", expr: "COUNT(1)"             }
            , { alias: "cid"  , expr: "CAST(NULL AS BIGINT)" }
            ]
        , FROM: [ { alias: "v", table: .variablesTable } ]
        , GROUP_BY:
            [ .variablesCategoryColumns[]
            | {                 table: "v", column: . } ]
        } | asSql | asPrettySqlArg)
        # assign unique id to every distinct category
        deepdive db assign_sequential_id \(.variablesCategoriesTable | @sh) cid 0
        " else "" end)

        # generate a table holding all distinct variables identified by @key columns
        # so a unique id can be assigned to each of them
        deepdive create table \(.variablesIdsTable | @sh) as \(
        { SELECT:
            [ (.variablesKeyColumns[]
            | { alias: ., table: "v", column: . }) # XXX we don't prefix user's columns (with _ like others) since they directly use this table and it can cause confusion
            , { alias: deepdiveVariableLabelColumn, expr:
                # boolean variables just take one label, so aggregate with AND
                ( if .variableType == "boolean" then "EVERY(\"v\".\(deepdiveVariableLabelColumn | asSqlIdent))"
                # categorical variables should point to the category id that has a true label column
                else "MIN(CASE WHEN \"v\".\(deepdiveVariableLabelColumn | asSqlIdent) THEN \"c\".\"cid\" ELSE NULL END)"
                end) }
            , { alias: deepdiveVariableFrequencyColumn, expr: "COUNT(1)" }
            , { alias: deepdiveVariableIdColumn, expr: "CAST(NULL AS BIGINT)" }
            ]
        , FROM: [ { alias: "v", table: .variablesTable } ]
        , JOIN:
            ( if .variableType == "boolean" then null else
                # categorical variables need a join with the categories table
                [ { LEFT_OUTER: { alias: "c", table: .variablesCategoriesTable }
                  , ON: { and: [ .variablesCategoryColumns[]
                               | { eq: [ { table: "c", column: "_\(.)" }
                                       , { table: "v", column: . } ]
                                 } ] }
                  } ]
            end)
        , GROUP_BY: [ .variablesKeyColumns[] | { column: . } ]
        } | asSql | asPrettySqlArg)
        "
    }
})

## variable_id_partition
# Grounding begins by counting the variables to partition a range of
# non-negative integers for assigning the variable ids.
| .deepdive_.execution.processes += {
    "process/grounding/variable_id_partition": {
        dependencies_: [
            # id partition depends on all distinct variables to be first identified
            $deepdive.schema.variables_[] | "process/grounding/variable/\(.variableName)/materialize"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        RANGE_BEGIN=0 \\
        partition_id_range \($deepdive.schema.variables_ | map(.variablesIdsTable | @sh) | join(" ")) | {
            # variable names
            set -- \($deepdive.schema.variables_ | map(.variableName | @sh) | join(" "))
            # record the base
            variableCountTotal=0
            while read table begin excludeEnd; do
                varName=$1; shift
                varPath=\"$DEEPDIVE_GROUNDING_DIR\"/variable/${varName}
                mkdir -p \"$varPath\"
                cd \"$varPath\"
                echo $begin                      >id_begin
                echo $excludeEnd                 >id_exclude_end
                echo $(( $excludeEnd - $begin )) >count
                variableCountTotal=$excludeEnd
            done
            # record the final count
            echo $variableCountTotal >\"$DEEPDIVE_GROUNDING_DIR\"/variable_count
        }
        "
    }
}


## variable/*/assign_id
# Each variable table then gets the range of integers assigned to the id column
# of every row.
| .deepdive_.execution.processes += merge($deepdive.schema.variables_[] | {
    "process/grounding/variable/\(.variableName)/assign_id": {
        dependencies_: [
            "process/grounding/variable_id_partition"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        cd \"$DEEPDIVE_GROUNDING_DIR\"/variable/\(.variableName | @sh)
        baseId=$(cat id_begin)

        # assign id to all distinct variables according to the paritition
        deepdive db assign_sequential_id \(.variablesIdsTable | @sh) \(deepdiveVariableIdColumn | @sh) $baseId
        "
    }
})

## variable_holdout
# Variables to holdout are recorded by executing either a user-defined
# (app-wide) holdout query, or by taking a random sample of a user-defined
# fraction.
# TODO easier way to do holdout per variable?
| .deepdive_.execution.processes += {
    "process/grounding/variable_holdout": {
        dependencies_: [
            $deepdive.schema.variables_[]
            | "process/grounding/variable/\(.variableName)/assign_id"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        deepdive create table \(deepdiveGlobalHoldoutTable | @sh) \\
            variable_id:BIGINT:'PRIMARY KEY' \\
            #
        deepdive create table \(deepdiveGlobalObservationTable | @sh) \\
            variable_id:BIGINT:'PRIMARY KEY' \\
            #
        \([ if $deepdive.calibration.holdout_query then
            # run user holdout query if configured
            "\($deepdive.schema.variables_
                | withRedefinitionsWithJoinsForIdColumns)
            \($deepdive.calibration.holdout_query)"
          else
            # otherwise, randomly select from evidence variables of each variable table
            $deepdive.schema.variables_[] | "
                INSERT INTO \(deepdiveGlobalHoldoutTable | asSqlIdent) \(
                { SELECT: [ { column: deepdiveVariableIdColumn } ]
                , FROM: [ { table: .variablesIdsTable } ]
                , WHERE:
                    [ { isntNull: { column: deepdiveVariableLabelColumn } }
                    , { lt: [ { expr: "RANDOM()" }
                            , { expr: $deepdive.calibration.holdout_fraction }
                            ]
                      }
                    ]
                } | asSql);
            "
          end
        , if $deepdive.calibration.observation_query then
            # run user holdout query if configured
            "\($deepdive.schema.variables_
                | withRedefinitionsWithJoinsForIdColumns)
            \($deepdive.calibration.holdout_query)"
          else empty
          end
        ] | map("deepdive sql \(asPrettySqlArg)") | join("\n"))
        "
    }
}

## variable/*/dump
# Then each variable table is dumped into a set of binary files for the inference engine.
| .deepdive_.execution.processes += merge($deepdive.schema.variables_[] | {
    "process/grounding/variable/\(.variableName)/dump": {
        dependencies_: [
            "process/grounding/variable_holdout"
          # XXX below can be omitted for now
          #, "process/grounding/variable/\(.variableName)/assign_id"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        varPath=\"$DEEPDIVE_GROUNDING_DIR\"/variable/\(.variableName | @sh)
        mkdir -p \"$varPath\"
        cd \"$varPath\"
        find . -name 'variables.part-*.bin.bz2' -exec rm -rf {} +
        export DEEPDIVE_LOAD_FORMAT=tsv
        export DEEPDIVE_UNLOAD_MATERIALIZED=false

        # dump the variables, joining the holdout query to determine the type of each variable
        deepdive compute execute \\
            input_sql=\(
            { SELECT:
                [ { column: "vid" }
                , { column: "variable_role" }
                , { alias: "init_value", expr:
                    "CASE WHEN variable_role = 0 THEN 0
                          ELSE (\(
                            if   .variableType == "boolean"     then "CASE WHEN label THEN 1 ELSE 0 END" # XXX a portable way to turn boolean to integers in SQL, CAST(label AS INT) does not work for MySQL
                            elif .variableType == "categorical" then "label"
                            else error("Internal error: Unknown variableType: \(.variableType)")
                            end
                            )) + 0.0
                      END" }
                , { column: "variable_type" }
                , { column: "cardinality" }
                ]
            , FROM:
                [ { alias: "variables", sql:
                    { SELECT:
                        [ { alias: "vid", column: deepdiveVariableIdColumn }
                        , { alias: "variable_role", expr:
                              "CASE WHEN observation.variable_id IS NOT NULL
                                     AND \"i\".\(deepdiveVariableLabelColumn | asSqlIdent) IS NOT NULL THEN 2
                                    WHEN holdout.variable_id IS NOT NULL THEN 0
                                    WHEN \"i\".\(deepdiveVariableLabelColumn | asSqlIdent) IS NOT NULL THEN 1
                                                                             ELSE 0
                                END" }
                        , { alias: "label", table: "i", column: deepdiveVariableLabelColumn }
                        , { alias: "variable_type", expr: (
                                if   .variableType == "boolean"     then 0
                                elif .variableType == "categorical" then 1
                                else error("Internal error: Unknown variableType: \(.variableType)")
                                end
                            ) }
                        , { alias: "cardinality", expr: (
                                if   .variableType == "boolean"     then 2
                                elif .variableType == "categorical" then "count" # TODO count the number of actual distinct values by .variablesCategoryColumns for this row
                                else error("Internal error: Unknown variableType: \(.variableType)")
                                end
                            ) }
                        ]
                    , FROM:
                        [ { alias: "i", table: .variablesIdsTable }
                        ]
                    , JOIN:
                        [ { LEFT_OUTER:
                            { alias: "holdout"
                            , table: deepdiveGlobalHoldoutTable
                            }
                          , ON: { eq:
                                    [ { table: "i", column: deepdiveVariableIdColumn }
                                    , { table: "holdout"  , column: "variable_id" }
                                    ]
                                }
                          }
                        , { LEFT_OUTER:
                            { alias: "observation"
                            , table: deepdiveGlobalObservationTable
                            }
                          , ON: { eq:
                                    [ { table: "i"  , column: deepdiveVariableIdColumn }
                                    , { table: "observation", column: "variable_id" }
                                    ]
                                }
                          }
                        ]
                    }
                  }
                ]
            } | asSql | asPrettySqlArg) \\
            command=\("
                format_converter variable /dev/stdin >(pbzip2 >variables.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)
            " | @sh) \\
            output_relation=
        "
    }

})


## variable/*/dump_domains
# Each categorical variable dumps an extra input for the inference engine that holds the domains.
| .deepdive_.execution.processes += merge($deepdive.schema.variables_[]
    | select(.variableType == "categorical") | {
    "process/grounding/variable/\(.variableName)/dump_domains": {
        dependencies_: [
            "process/grounding/variable/\(.variableName)/assign_id"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}
        varPath=\"$DEEPDIVE_GROUNDING_DIR\"/variable/\(.variableName | @sh)
        mkdir -p \"$varPath\"
        cd \"$varPath\"
        find . -name 'domains.part-*.bin.bz2' -exec rm -rf {} +
        export DEEPDIVE_LOAD_FORMAT=tsv
        export DEEPDIVE_UNLOAD_MATERIALIZED=false

        # dump the categorical variable domains, joining the categories table for their ids
        deepdive compute execute \\
            input_sql=\(
            { SELECT:
                [ { alias: "vid",  table: "i", column: deepdiveVariableIdColumn }
                , { alias: "cardinality", expr: "COUNT(c.cid)" }
                , { alias: "cids", expr: "ARRAY_AGG(c.cid)" }
                ]
            , FROM: [ { alias: "v", table: .variablesTable } ]
            , JOIN:
                # variable ids
                [ { LEFT_OUTER: { alias: "i", table: .variablesIdsTable }
                  , ON: { and:  [ .variablesKeyColumns[]
                                | { eq: [ { table: "i", column: . }
                                        , { table: "v", column: . }
                                        ] }
                                ] } }
                # category ids are necessary to find the inference result corresponding to the variable
                , { LEFT_OUTER: { alias: "c", table: .variablesCategoriesTable }
                  , ON: { and:  [ .variablesCategoryColumns[]
                                | { eq: [ { table: "c", column: "_\(.)" }
                                        , { table: "v", column: . }
                                        ] }
                                ] } }
                ]
            , GROUP_BY: [ { table: "i", column: deepdiveVariableIdColumn } ]
            } | asSql | asPrettySqlArg) \\
            command=\("
                exec cat >domains.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.tsv  # TODO @feiranwang remove this line once format_converter is ready
                format_converter domain /dev/stdin >(pbzip2 >domains.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)
            " | @sh) \\
            output_relation=
        "
    }

})


###############################################################################

## factor/*/materialize
# Each inference rule's SQL query is run to materialize the factors and the
# distinct weights used in them.
| .deepdive_.execution.processes += merge($deepdive.inference.factors_[]
    | [ .input_[]
      | ltrimstr("data/")
      | $deepdive.schema.variables_byName[.]
      | select(type != "null")
      ] as $schemaVariablesForThisFactor
    | {
    # add a process for grounding factors
    "process/grounding/factor/\(.factorName)/materialize": {
        # materializing each factor requires the dependent variables to have their id assigned
        dependencies_: [
            $schemaVariablesForThisFactor[]
            # the involved variables must have their ids all assigned
            | "process/grounding/variable/\(.variableName)/assign_id"?
        ],
        # other non-variable tables are also necessary
        input_: [ .input_[]
            | select(ltrimstr("data/") | in($deepdive.schema.variables_byName) | not)
        ],
        style: "cmd_extractor", cmd: "
            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

            # materialize factors using user input_query that pulls in assigned ids to involved variables
            deepdive create table \(.factorsTable | @sh) as \(
            # allow .input_query to refer to the assigned variable ids by redefining the variable table names with SQL CTE
            "\($schemaVariablesForThisFactor |
                withRedefinitionsWithJoinsForIdColumns)
            \(.input_query)" | asPrettySqlArg)

            # find distinct weights for the factors into a separate table
            deepdive create table \(.weightsTable | @sh) as \(
                { SELECT:
                    [ ( .weight_.params[] | { column: . } )
                    , { alias: "isfixed"  , expr: .weight_.is_fixed      }
                    , { alias: "initvalue", expr: .weight_.init_value    }
                    , { alias: "wid"      , expr: "CAST(NULL AS BIGINT)" }
                    ]
                # when weight is parameterized, find all distinct ones
                , FROM:
                    (if .weight_.params | length == 0 then [] else
                        [ { table: .factorsTable } ]
                    end)
                , GROUP_BY: [ ( .weight_.params[] | { column: . } ) ]
                } | asSql | asPrettySqlArg)
        "
    }
})


## weight_id_partition
# The weight ids must be first partitioned by counting them.
| .deepdive_.execution.processes += {
    "process/grounding/weight_id_partition": {
        dependencies_: [
            $deepdive.inference.factors_[]
            | "process/grounding/factor/\(.factorName)/materialize"
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        # partition the id range for weights
        RANGE_BEGIN=0 RANGE_STEP=1 \\
        partition_id_range \([ $deepdive.inference.factors_[] | "\(.weightsTable | @sh)" ] | join(" ")) | {
            # factor names
            set -- \($deepdive.inference.factors_ | map(.factorName | @sh) | join(" "))
            weightsCountTotal=0
            while read table begin excludeEnd; do
                factor=$1; shift
                facPath=\"$DEEPDIVE_GROUNDING_DIR\"/factor/${factor}
                mkdir -p \"$facPath\"
                cd \"$facPath\"
                echo $begin                      >weights_id_begin
                echo $excludeEnd                 >weights_id_exclude_end
                echo $(( $excludeEnd - $begin )) >weights_count
                weightsCountTotal=$excludeEnd
            done
            echo $weightsCountTotal >\"$DEEPDIVE_GROUNDING_DIR\"/factor/weights_count
        }
        "
    }
}

## global_weight_table
# To view the weights learned by the inference engine later, set up an app-wide table.
| .deepdive_.execution.processes += {
    "process/grounding/global_weight_table": {
        dependencies_: [
            $deepdive.inference.factors_[] |
            if .function_.name == "multinomial" then
                "process/grounding/factor/\(.factorName)/assign_weight_id"
            else
                "process/grounding/factor/\(.factorName)/materialize"
            end
        ],
        style: "cmd_extractor", cmd: "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

        # set up a union view for all weight tables (\(deepdiveGlobalWeightsTable | asSqlIdent))
        deepdive create view \(deepdiveGlobalWeightsTable | @sh) as \(
            [ $deepdive.inference.factors_[] |
                { SELECT:
                    [ { column: "wid" }
                    , { column: "isfixed" }
                    , { column: "initvalue" }
                    , { alias: "description", expr: factorWeightDescriptionSqlExpr
                      }
                    , if .function_.name != "multinomial" then
                        # TODO maybe '1' is a better one for boolean variables?
                        { alias: "categories", expr: "NULL" }
                    else # multinomial factor weights table have a "categories" column
                          # FIXME this no longer exists
                        { column: "categories" }
                    end
                    ]
                , FROM:
                    [ { table: .weightsTable }
                    ]
                } | asSql | "(\(.))"
            ] | join("\nUNION ALL\n") | asPrettySqlArg)
        "
    }
}

## factor/*/assign_weight_id
# Each inference rule gets its weight ids actually assigned.
| .deepdive_.execution.processes += merge($deepdive.inference.factors_[] | {
    "process/grounding/factor/\(.factorName)/assign_weight_id": {
        dependencies_: [
            "process/grounding/weight_id_partition"
        ],
        style: "cmd_extractor", cmd: "
            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}

            cd \"$DEEPDIVE_GROUNDING_DIR\"/factor/\(.factorName | @sh)
            baseId=$(cat weights_id_begin)
            inc=1

            # assign weight ids according to the partition
            deepdive db assign_sequential_id \(.weightsTable | @sh) wid $baseId $inc
        "
    }
})


## factor/*/dump
# The factors are dumped into a set of binary files for the inference engine.
| .deepdive_.execution.processes += merge($deepdive.inference.factors_[] | {
    # add a process for grounding factors and weights
    "process/grounding/factor/\(.factorName)/dump": {
        dependencies_: [
            "process/grounding/factor/\(.factorName)/assign_weight_id"
        ],
        style: "cmd_extractor", cmd: "
            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}
            facPath=\"$DEEPDIVE_GROUNDING_DIR\"/factor/\(.factorName | @sh)
            mkdir -p \"$facPath\"
            cd \"$facPath\"
            find . \\( -name  'factors.part-*.bin.bz2' \\
                    -o -name 'nfactors.part-*'         \\
                    -o -name   'nedges.part-*'         \\
                   \\) -exec rm -rf {} +
            export DEEPDIVE_LOAD_FORMAT=tsv
            export DEEPDIVE_UNLOAD_MATERIALIZED=false

            # dump the factors joining the assigned weight ids, converting into binary format for the inference engine
            deepdive compute execute \\
                input_sql=\(
                    { SELECT:
                        [ { alias: "weight_id", table: "weights", column: "wid" }
                        , ( .function_.variables[] |
                            { table: "factors", column: .columnId }
                          )
                        ]
                    , FROM:
                        [ { alias: "factors", table: .factorsTable }
                        , { alias: "weights", table: .weightsTable }
                        ]
                    , WHERE:
                        [ .weight_.params[] |
                            { eq: [ { table: "factors", column: . }
                                  , { table: "weights", column: . }
                                  ]
                            }
                        ]
                    } | asSql | asPrettySqlArg) \\
                command=\("
                    # also record the factor count
                    tee >(wc -l >nfactors.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}) |
                    format_converter factor /dev/stdin >(pbzip2 >factors.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2) \(.function_.id
                        ) \(.function_.variables | length
                        ) original \(.function_.variables | map(if .isNegated then "0" else "1" end) | join(" ")
                        ) |
                    # and the edge count
                    tee nedges.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}
                " | @sh) \\
                output_relation=
        "
    }
})

## factor/*/dump_weights
# The factors and weights are dumped into a set of binary files for the inference engine.
| .deepdive_.execution.processes += merge($deepdive.inference.factors_[] | {
    # add a process for grounding factors and weights
    "process/grounding/factor/\(.factorName)/dump_weights": {
        dependencies_: [
            "process/grounding/factor/\(.factorName)/assign_weight_id"
        ],
        style: "cmd_extractor", cmd: "
            : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}
            facPath=\"$DEEPDIVE_GROUNDING_DIR\"/factor/\(.factorName | @sh)
            mkdir -p \"$facPath\"
            cd \"$facPath\"
            find . \\( -name  'weights.part-*.bin.bz2' \\
                   \\) -exec rm -rf {} +
            export DEEPDIVE_LOAD_FORMAT=tsv
            export DEEPDIVE_UNLOAD_MATERIALIZED=false

            # flag that signals whether to reuse weights or not
            reuseFlag=\"$DEEPDIVE_GROUNDING_DIR\"/factor/weights.reuse

            # dump the weights (except the description column), converting into binary format for the inference engine
            deepdive compute execute \\
                input_sql=\"$(if [[ -e \"$reuseFlag\" ]]; then
                    echo \(
                    # dump weights with initvalue from previously learned ones
                    { SELECT:
                        [ { table: "w", column: "wid" }
                        , { expr: "CASE WHEN w.isfixed THEN 1 ELSE 0 END" }
                        , { expr: "COALESCE(reuse.weight, w.initvalue, 0)" }
                        ]
                    , FROM: [ { alias: "w", table: .weightsTable } ]
                    , JOIN: { LEFT_OUTER: { alias: "reuse", table: deepdiveReuseWeightsTable }
                            , ON: { and: [ { eq: [ { table: "reuse", column: "description" }
                                                 , { expr: factorWeightDescriptionSqlExpr }
                                                 ] }
                                         , if .function_.name == "multinomial" then
                                           { or: [ { isNull: { table: "reuse", column: "categories" } }
                                                   , { eq: [ { table: "reuse", column: "categories" }
                                                           , { table: "w",     column: "categories" }
                                                           ] }
                                                 ] }
                                           else empty end
                                         ] }
                            }
                    } | asSql | asPrettySqlArg)
                else
                    echo \(
                    # dump weights from scratch
                    { SELECT:
                        [ { column: "wid" }
                        , { expr: "CASE WHEN isfixed THEN 1 ELSE 0 END" }
                        , { expr: "COALESCE(initvalue, 0)" }
                        ]
                    , FROM: [ { table: .weightsTable } ]
                    } | asSql | asPrettySqlArg)
                fi)\" \\
                command=\("
                    format_converter weight /dev/stdin >(pbzip2 >weights.part-${DEEPDIVE_CURRENT_PROCESS_INDEX}.bin.bz2)
                " | @sh) \\
                output_relation=
        "
    }
})

###############################################################################

# Finally, put together everything dumped into a layout the inference engine can easily load from
| .deepdive_.execution.processes += {
    "process/grounding/combine_factorgraph": {
        dependencies_: [(
            $deepdive.schema.variables_[]
            | "process/grounding/variable/\(.variableName)/dump"
            , (select(.variableType == "categorical")
            | "process/grounding/variable/\(.variableName)/dump_domains")
        ), (
            $deepdive.inference.factors_[]
            | "process/grounding/factor/\(.factorName)/dump"
            , "process/grounding/factor/\(.factorName)/dump_weights"
        ), (
            "process/grounding/global_weight_table"
        )],
        output_: "model/factorgraph",
        style: "cmd_extractor", cmd: (
            ([$deepdive.schema.variables_[] | .variableName | @sh] | join(" ")) as $variableNames |
            ([$deepdive.inference.factors_[] | .factorName  | @sh] | join(" ")) as $factorNames   |
        "
        : ${DEEPDIVE_GROUNDING_DIR:=\"$DEEPDIVE_APP\"/run/model/grounding}
        : ${DEEPDIVE_FACTORGRAPH_DIR:=\"$DEEPDIVE_APP\"/run/model/factorgraph}

        # create a fresh empty directory for the new combined factor graph
        rm -rf   \"$DEEPDIVE_FACTORGRAPH_DIR\"
        mkdir -p \"$DEEPDIVE_FACTORGRAPH_DIR\"
        cd \"$DEEPDIVE_FACTORGRAPH_DIR\"

        # create symlinks to the grounded binaries by enumerating variables and factors
        for v in \($variableNames); do
            mkdir -p {variables,domains}/\"$v\"
            find \"$DEEPDIVE_GROUNDING_DIR\"/variable/\"$v\" \\
                -name 'variables.part-*.bin.bz2' -exec ln -sfnv -t variables/\"$v\"/ {} + \\
                -o \\
                -name   'domains.part-*.bin.bz2' -exec ln -sfnv -t   domains/\"$v\"/ {} + \\
                #
        done
        for f in \($factorNames); do
            mkdir -p {factors,weights}/\"$f\"
            find \"$DEEPDIVE_GROUNDING_DIR\"/factor/\"$f\" \\
                -name 'factors.part-*.bin.bz2' -exec ln -sfnv -t factors/\"$f\"/ {} + \\
                -o \\
                -name 'weights.part-*.bin.bz2' -exec ln -sfnv -t weights/\"$f\"/ {} + \\
                #
        done

        # generate the metadata for the inference engine
        {
            # first line with counts of variables and edges in the grounded factor graph
            cd \"$DEEPDIVE_GROUNDING_DIR\"
            sumup() { { tr '\\n' +; echo 0; } | bc; }
            counts=()
            counts+=($(cat factor/weights_count))
            # sum up the number of factors and edges
            counts+=($(cat variable_count))
            cd factor
            counts+=($(find \($factorNames) -name 'nfactors.part-*' -exec cat {} + | sumup))
            counts+=($(find \($factorNames) -name 'nedges.part-*'   -exec cat {} + | sumup))
            (IFS=,; echo \"${counts[*]}\")
            # second line with file paths
            paths=(\"$DEEPDIVE_FACTORGRAPH_DIR\"/{weights,variables,factors,edges,domains})
            (IFS=,; echo \"${paths[*]}\")
        } >meta
        ")
    }
}

## from_grounding
# A nominal process to make it easy to redo the grounding
# TODO remove this once deepdive-do supports process groups or pipelines
| .deepdive_.execution.processes += {
    "process/grounding/from_grounding": {
        style: "cmd_extractor", cmd: ": no-op"
    }
}

end
