# example DeepDive application for finding spouse relationships in news articles
@source
articles(
    @key
    id text,
    @searchable
    content text
    # TODO more fields if needed
).

@source
spouses_dbpedia(
    @key
    person1_name text,
    @key
    person2_name text
).

## NLP markup #################################################################
sentences( doc_id         text
         , sentence_index int
         , sentence_text  text
         , tokens         text[]
         , lemmas         text[]
         , pos_tags       text[]
         , ner_tags       text[]
         , doc_offsets    int[]
         , dep_types      text[]
         , dep_tokens    int[]
         ).

function nlp_markup over ( doc_id text, content text )
                 returns rows like sentences
  implementation "udf/nlp_markup.sh" handles tsv lines.

sentences +=
  nlp_markup(doc_id, content) :-
  articles(doc_id, content).
###############################################################################

## Candidate mapping ##########################################################
@extraction
person_mention(
    @key
    mention_id text,
    mention_text text,
    @references(relation="sentences", column="doc_id", alias="appears_in")
    doc_id text,
    @references(relation="sentences", column="sentence_index")
    sentence_index int,
    begin_index int,
    end_index int
).

function map_person_mention over (
        doc_id text,
        sentence_index int,
        tokens text[],
        ner_tags text[]
    )
    returns rows like person_mention
    implementation "udf/map_person_mention.py" handles tsv lines.

person_mention += map_person_mention(
    doc_id, sentence_index, tokens, ner_tags
) :- sentences(doc_id, sentence_index, _, tokens, _, _, ner_tags, _, _, _).

@extraction
spouse_candidate(
    # TODO Here, ideally ddlog should allow us to write something like:
    #   p1 person_mention, p2 person_mention
    # then expand them into their multi-@key columns by itself.
    @key
    @references(relation="person_mention", column="mention_id", alias="p1")
    p1_id text,
    @key
    @references(relation="person_mention", column="mention_id", alias="p2")
    p2_id text
).

spouse_candidate(p1, p2) :-
    person_mention(p1, _, same_doc, same_sentence, p1_begin, _),
    person_mention(p2, _, same_doc, same_sentence, p2_begin, _),
    p1_begin != p2_begin.
###############################################################################

## Feature Extraction #########################################################

# Feature extraction (using DDLIB via a UDF) at the relation level
# TODO: add @extraction flag here?
spouse_feature(
    @key
    @references(relation="person_mention", column="mention_id", alias="p1")
    p1_id text,
    @key
    @references(relation="person_mention", column="mention_id", alias="p2")
    p2_id text,
    feature text
).

function extract_spouse_features over (
        p1_id text,
        p2_id text,
        p1_begin_index int,
        p1_end_index int,
        p2_begin_index int,
        p2_end_index int,
        doc_id text,
        sent_index int,
        tokens text[],
        lemmas text[],
        pos_tags text[],
        ner_tags text[],
        dep_types text[],
        dep_tokens int[]
    )
    returns rows like spouse_feature
    implementation "udf/extract_spouse_features.py" handles tsv lines.

spouse_feature += extract_spouse_features(
  p1_id, p2_id, p1_begin_index, p1_end_index, p2_begin_index, p2_end_index,
  doc_id, sent_index, tokens, lemmas, pos_tags, ner_tags, dep_types, dep_tokens) :- 
  person_mention(p1_id, _, doc_id, sent_index, p1_begin_index, p1_end_index),
  person_mention(p2_id, _, doc_id, sent_index, p2_begin_index, p2_end_index),
  sentences(doc_id, sent_index, _, tokens, lemmas, pos_tags, ner_tags, _, dep_types, dep_tokens
).
###############################################################################

## Distant Supervision ########################################################

# distant supervision using data from DBpedia
spouse_label_dbpedia(
    @key
    p1_id text,
    @key
    p2_id text,
    label int
).

spouse_label_dbpedia(p1,p2,1) :-
  spouse_candidate(p1,p2),
  person_mention(p1,p1_name,_,_,_,_),
  person_mention(p2,p2_name,_,_,_,_),
  spouses_dbpedia(n1, n2),
  [lower(n1) = lower(p1_name),
    lower(n2) = lower(p2_name);
    lower(n2) = lower(p1_name),
    lower(n1) = lower(p2_name)].

# TODO

# supervision by heuristic rules in a UDF
function supervise over (
        p1_id text, p1_begin int, p1_end int,
        p2_id text, p2_begin int, p2_end int,
        doc_id         text,
        sentence_index int,
        sentence_text  text,
        tokens         text[],
        lemmas         text[],
        pos_tags       text[],
        ner_tags       text[],
        dep_types      text[],
        dep_tokens    int[]
    ) returns (
        p1_id text, p2_id text, label int, rule_id text
    )
    implementation "udf/supervise_spouse.py" handles tsv lines.

spouse_label_heuristic(
    @key
    p1_id text,
    @key
    p2_id text,
    label int,
    rule_id text
).

spouse_label_heuristic += supervise(
    p1_id, p1_begin, p1_end,
    p2_id, p2_begin, p2_end,
    doc_id, sentence_index, sentence_text,
    tokens, lemmas, pos_tags, ner_tags, dep_types, dep_token_indexes
) :- spouse_candidate(p1_id, p2_id),
    person_mention(p1_id, p1_text, doc_id, sentence_index, p1_begin, p1_end),
    person_mention(p2_id, p2_text,      _,              _, p2_begin, p2_end),
    sentences(
        doc_id, sentence_index, sentence_text,
        tokens, lemmas, pos_tags, ner_tags, _, dep_types, dep_token_indexes
    ).

# We do majority vote to aggregate labels from distant supervision
spouse_label(
    @key
    p1_id text,
    @key
    p2_id text,
    label boolean,
    rule_id text
).

# TODO: Remove these after merging latest pull request (#468)!
spouse_union(
  @key
  p1_id text,
  @key
  p2_id text,
  label int,
  rule_id text
).
spouse_agg(
  @key
  p1_id text,
  @key
  p2_id text,
  label int,
  rule_id text
).

# We first take the union of the labels generated by our distant supervision rules
spouse_union(p1_id, p2_id, label, "dbpedia_spouse") :-
  spouse_label_dbpedia(p1_id, p2_id, label).
spouse_union(p1_id, p2_id, label, rule_id) :-
  spouse_label_heuristic(p1_id, p2_id, label, rule_id).

# Next, we take the union spouse_candidate to include any unlabeled examples
# We sum the labels $l \in {-1,0,1}$ for each example to do majority vote
spouse_union(p1_id, p2_id, 0, NULL) :-
  spouse_candidate(p1_id, p2_id).
spouse_agg(p1_id, p2_id, SUM(label), ARRAY_AGG(rule_id)) :-
  spouse_union(p1_id, p2_id, label, rule_id).

# We binarize the sums
spouse_label(p1_id, p2_id, TRUE, rule_id) :-
  spouse_agg(p1_id, p2_id, label, rule_id), [label > 0].
spouse_label(p1_id, p2_id, NULL, rule_id) :-
  spouse_agg(p1_id, p2_id, label, rule_id), [label = 0].
spouse_label(p1_id, p2_id, FALSE, rule_id) :-
  spouse_agg(p1_id, p2_id, label, rule_id), [label < 0].
###############################################################################

## Inference Rules ############################################################

# We specify the random variables in our factor graph, which we wish to do inference over
has_spouse?(p1_id text, p2_id text).

# We specify the labels for the spouse relation
@label(l)
has_spouse(p1_id, p2_id) :- spouse_label(p1_id, p2_id, l, rule_id).

# Features
@weight(f)
has_spouse(p1_id, p2_id) :-
  spouse_candidate(p1_id, p2_id),
  spouse_feature(p1_id, p2_id, f).

# Inference rule: Symmetry
@weight(3.0)
has_spouse(p1_id, p2_id) => has_spouse(p2_id, p1_id) :-
  spouse_candidate(p1_id, p2_id).

# Inference rule: Only one marriage
@weight(-1.0)
has_spouse(p1_id, p2_id) => has_spouse(p1_id, p3_id) :-
  spouse_candidate(p1_id, p2_id),
  spouse_candidate(p1_id, p3_id).
