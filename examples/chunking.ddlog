// chunking example
// https://github.com/HazyResearch/deepdive/tree/master/examples/chunking

words_raw(
  word_id bigserial,
  word text,
  pos text,
  tag text).

words(
  sent_id bigint,
  word_id bigint,
  word text,
  pos text,
  true_tag text).

word_features(
  word_id bigint,
  feature text).

tag?(word_id bigint) Categorical(13).

function ext_training
  over rows like words_raw
  returns rows like words
  implementation "udf/ext_training.py" handles tsv lines.

words +=
  ext_training(wid, word, pos, tag) :- words_raw(wid, word, pos, tag).

function ext_features
  over (word_id1 bigint, word1 text, pos1 text, word2 text, pos2 text)
  returns rows like word_features
  implementation "udf/ext_features.py" handles tsv lines.

word_features +=
  ext_features(word_id1, word1, pos1, word2, pos2) :-
  words(sent_id, word_id1, word1, pos1, tag1),
  words(sent_id, word_id2, word2, pos2, tag2).

tag(word_id) = tag :- words(word_id, a, b, c, tag).

@weight(f)
tag(word_id) :- word_features(word_id, f).
