<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="DeepDive" />
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="http://deepdive.stanford.edu/stylesheets/application.css" />
    <link rel="canonical" href="http://deepdive.stanford.edu">
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script>
    <script src="http://deepdive.stanford.edu/javascripts/application.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DeepDive</title>
  </head>

  <body>
      <script type="text/javascript">
window.analytics||(window.analytics=[]),window.analytics.methods=["identify","track","trackLink","trackForm","trackClick","trackSubmit","page","pageview","ab","alias","ready","group","on","once","off"],window.analytics.factory=function(t){return function(){var a=Array.prototype.slice.call(arguments);return a.unshift(t),window.analytics.push(a),window.analytics}};for(var i=0;i<window.analytics.methods.length;i++){var method=window.analytics.methods[i];window.analytics[method]=window.analytics.factory(method)}window.analytics.load=function(t){var a=document.createElement("script");a.type="text/javascript",a.async=!0,a.src=("https:"===document.location.protocol?"https://":"http://")+"d2dq2ahtl5zl1z.cloudfront.net/analytics.js/v1/"+t+"/analytics.min.js";var n=document.getElementsByTagName("script")[0];n.parentNode.insertBefore(a,n)},window.analytics.SNIPPET_VERSION="2.0.8",
window.analytics.load("h6uwk48gwg");
window.analytics.page();
</script>
      <a href="https://github.com/hazyresearch/deepdive" target="_blank"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>

      <div id="header">
        <div class="container">
          <row>
            <div class="col-md-4 col-md-offset-1">
              <a href="http://deepdive.stanford.edu/" class="deepdive-logo">
              <img src="http://deepdive.stanford.edu/images/header_logo.png" style="width: 250px;"/>
              </a> 
            </div>
            <div class="col-md-6 col-md-offset-1">
              <ul class="list-unstyled list-inline" id="header-nav">
                <li><a href="http://deepdive.stanford.edu/index.html">Home</a></li>
                <li><a href="http://deepdive.stanford.edu/doc/installation.html">Download</a></li>
                <li><a href="http://deepdive.stanford.edu/index.html#documentation">Documentation</a></li>
                <li><a href="https://mailman.stanford.edu/mailman/listinfo/deepdive-list" target="_blank">Mailing List</a></li>
              </ul>
              
            </div>
          </row>
        </div>
      </div>

      <section id="main">
        <div class="container">
          <row>
            <div class="col-md-10 col-md-offset-1">
              <h1>Example Application: A Mention-Level Extraction System</h1>

<p>In this document, we will walk through how to <strong>build an application to extract mention-level <code>has_spouse</code> relation from text</strong> in DeepDive. By following this document you can learn about basic DeepDive functionality.</p>

<p>If you are not familiar with basic concepts in DeepDive (such as feature extraction and inference rules), please start from the <a href="walkthrough.html">walkthrough</a>.</p>

<!-- read our [homepage](http://deepdive.stanford.edu/index.html) and this [overview](overview.html) first. -->

<p><a id="high_level_picture" href="#"> </a></p>

<h2>High-level picture of the application</h2>

<p>This tutorial will walk you through building a full DeepDive application that extracts <strong>mention-level</strong> <code>has_spouse</code> relationships from raw text. We use news articles as our input data and want to extract all pairs of people that participate in a <code>has_spouse</code> relation, for example <em>Barack Obama</em> and <em>Michelle Obama</em>. This example should can be easily translated into relation extraction in other domains, such as extracting interactions between drugs, or relationships among companies.</p>

<p>Note that in this section we are going to build an application that extract <em>plausible</em> mention-level relations, but <em>with rather low quality</em>.</p>

<p><a id="dataflow" href="#"> </a></p>

<p>On a high level, the application will perform following steps on the data:</p>

<ol>
<li>Data preprocessing: prepare parsed sentences.</li>
<li>Feature extraction: 

<ul>
<li>Extract mentions of people in the text</li>
<li>Extract all candidate pairs of people that possibly participate in a <code>has_spouse</code> relation</li>
<li>Extract features for <code>has_spouse</code> candidates</li>
<li>Prepare training data by <a href="general/relation_extraction.html">distant supervision</a> using a knowledge base</li>
</ul></li>
<li>Generate factor graphs by inference rules</li>
<li>statistical inference and learning</li>
<li>Generate results</li>
</ol>

<p>For simplicity, we will start from preprocessed sentence data (starting
from step 2). If our input is raw text articles, we also need to run
natural language processing in order to extract candidate pairs and
features. If you want to learn how NLP extraction can be done in
DeepDive (starting from step 1), you can refer to the appendix: <a href="walkthrough-extras.html#nlp_extractor">Data preprocessing using NLP extractor in DeepDive</a>.</p>

<p>The full application is also available in the folder <code>DEEPDIVE_HOME/examples/spouse_example</code>, which contains all possible implementations in <a href="extractors.html">different types of extractors</a>. In this document, we only introduce the default extractor type (<code>json_extractor</code>), which correspond to <code>DEEPDIVE_HOME/examples/spouse_example/default_extractor</code> in your DeepDive directory.</p>

<h3>Contents</h3>

<ul>
<li><a href="#preparation">Preparation</a>:

<ul>
<li><a href="#installing">Installing DeepDive</a><br></li>
<li><a href="#newapp">Creating a new DeepDive application</a></li>
</ul></li>
<li><a href="#implement_dataflow">Implement the data flow</a>:

<ol>
<li><a href="#loading_data">Data preprocessing</a></li>
<li><a href="#feature_extraction">Feature extraction</a>

<ul>
<li><a href="#people_extractor">Adding a people extractor</a></li>
<li><a href="#candidate_relations">Extracting candidate relations</a></li>
<li><a href="#candidate_relation_features">Adding features for candidate relations</a></li>
</ul></li>
<li><a href="#inference_rules">Writing inference rules for factor graph generation</a></li>
<li><a href="#learning_inference">Statistical inference and learning</a></li>
<li><a href="#get_result">Get and check results</a></li>
</ol></li>
</ul>

<p>Other sections:</p>

<ul>
<li><a href="walkthrough-improve.html">How to examine / improve results</a></li>
<li><a href="walkthrough-extras.html">Extras: preprocessing, NLP, pipelines, debugging extractor</a></li>
<li><a href="walkthrough.html">Go back to the Walkthrough</a></li>
</ul>

<h2>Preparation</h2>

<p><a id="installing" href="#"> </a></p>

<h3>Installing DeepDive</h3>

<p>Start by <a href="installation.html">downloading and installing DeepDive on your machine</a>. In the rest of this tutorial, you should have a <code>deepdive</code> directory as your working directory (you cannot rename the folder to other names). Assume the path to your <code>deepdive</code> directory is <code>$DEEPDIVE_HOME</code>.</p>

<p>We will be using PostgreSQL as our primary database in this example. If you followed the DeepDive installation guide and passed all tests then your PostgreSQL server should be running already.</p>

<!-- <a id="setup" href="#"> </a>

### Setting up the database

We will be using PostgreSQL as our primary database in this example. If you followed the DeepDive installation guide and passed all tests then your PostgreSQL server should be running already. Let's start by creating a new database called `deepdive_spouse` by typing in command line:

```bash
createdb deepdive_spouse
```

 -->

<div id="newapp" href="#"> </div>

<h3>Creating a new DeepDive application</h3>

<p>Start by creating a new folder <code>app/spouse</code> in the DeepDive directory for your application. Assume your DeepDive directory is <code>$DEEPDIVE_HOME</code>.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="nb">cd</span> <span class="nv">$DEEPDIVE_HOME</span>
mkdir -p app/spouse   <span class="c"># make folders recursively</span>
<span class="nb">cd </span>app/spouse
</code></pre></div>
<p>DeepDive&#39;s main entry point is a file called <code>application.conf</code> which contains database connection information as well as your feature extraction and inference rule pipelines. It is often useful to have a small <code>run.sh</code> script that loads environment variables and executes the DeepDive pipeline. We provide simple templates for both of these to copy and modify. Copy these templates to our directory by the following commands: </p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">cp ../../examples/template/application.conf .
cp ../../examples/template/run.sh .
cp ../../examples/template/env.sh .
</code></pre></div>
<p>The <code>env.sh</code> file configures environment variables that will be used in this application. There is a placeholder line <code>DBNAME=</code> in that file, modify <code>env.sh</code> and fill it with your database name:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># File: env.sh</span>
...
<span class="nb">export </span><span class="nv">DBNAME</span><span class="o">=</span>deepdive_spouse   <span class="c"># modify this line</span>
...
</code></pre></div>
<p>Note that in the <code>run.sh</code> file it defines environment variables <code>APP_HOME</code> which is our current directory <code>app/spouse</code>, and <code>DEEPDIVE_HOME</code> which is the home directory of DeepDive. We will use these variables later.</p>

<p>You can now try executing the <code>run.sh</code> file:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">./run.sh
</code></pre></div>
<p>Because you have not defined any extractors or inference rules you will not see meaningful results, but DeepDive should run successfully from end to end and you should be able to see a summary report such as:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">15:57:55 [profiler] INFO  --------------------------------------------------
15:57:55 [profiler] INFO  Summary Report
15:57:55 [profiler] INFO  --------------------------------------------------
</code></pre></div>
<p><a id="implement_dataflow" href="#"> </a></p>

<h2>Implement the Data Flow</h2>

<p>Now let&#39;s start implementing the <a href="#dataflow">data flow</a> for this KBC application.</p>

<p><a id="loading_data" href="#"> </a></p>

<h3>Data preprocessing</h3>

<p>In this example we will be using raw text from a couple of New York Times articles. Note that there is nothing special about our data set, and you are free to use whatever raw text data you want. Let&#39;s copy the data into our directory, and load it into the database. </p>

<p>We have prepared everything to free developers from data preprocessing. Copy prepared data and scripts from DeepDive <code>DEEPDIVE_HOME/example/spouse_example/</code> folder into <code>DEEPDIVE_HOME/app/spouse/</code>, by typing:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">cp -r ../../examples/spouse_example/data .
cp ../../examples/spouse_example/schema.sql .
cp ../../examples/spouse_example/setup_database.sh .
</code></pre></div>
<p>Then, execute the script <code>setup_database.sh</code>, which will get all the preprocessed data ready:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">sh setup_database.sh deepdive_spouse
</code></pre></div>
<p>Now following relations are provided in the database dump:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">                     List of relations
 Schema |        Name         | Type  |  Owner   | Storage
--------+---------------------+-------+----------+---------
 public | articles            | table | deepdive | heap
 public | has_spouse          | table | deepdive | heap
 public | has_spouse_features | table | deepdive | heap
 public | people_mentions     | table | deepdive | heap
 public | sentences           | table | deepdive | heap
(5 rows)
</code></pre></div>
<p>Among these relations: </p>

<ul>
<li><code>articles</code> contains article data</li>
<li><code>sentences</code> contains processed sentence data by an <a href="walkthrough-extras.html#nlp_extractor">NLP extractor</a>. This table contains tokenized words, lemmatized words, POS tags, NER tags, dependency paths for each sentence.</li>
<li>Other tables are currently empty, and during feature extraction step they will be filled up.</li>
</ul>

<p>For a detailed reference of how these tables are created and loaded, refer to <a href="walkthrough-extras.html#data_tables">Preparing Data Tables</a> in the extra section.</p>

<p><a id="feature_extraction" href="#"> </a></p>

<h3>Feature Extraction</h3>

<p>Our next task is to write several <a href="extractors.html">extractors</a> in
DeepDive for feature extraction. On a high
level, each extractor performs a user-defined function (UDF) on an input
query against database, <strong>in a row-wise manner</strong>. One may think of an
extractor as a function which <em>maps one input tuple (one row in input
SQL query)</em> to one or more output tuples, similar to a <code>map</code> or
<code>flatMap</code> function in functional programming languages (or &quot;Map&quot; in
MapReduce).</p>

<p><a id="people_extractor" href="#"> </a></p>

<h4>Adding a people extractor</h4>

<p>We first need to recognize the person mentions in the article. Given a
set of sentences as described above, the person mention extractor will
populate a relation people_mention that contains an encoding of the
mentions. In this example, we will build a simple person recognizer that
just uses the <a href="#loading_data">NER tags</a> from the
underlying NLP toolkit. We could do something more sophisticated, but we
just want to illustrate the basic concepts.</p>

<p><strong>Input:</strong> sentences along with NER tags. Specically, each line in the input to this extractor UDF is a row in <code>sentence</code> table in JSON format, e.g.:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{&quot;sentence_id&quot;:&quot;118238@10&quot;,&quot;words&quot;:[&quot;Sen.&quot;,&quot;Barack&quot;,&quot;Obama&quot;,&quot;and&quot;,&quot;his&quot;,&quot;wife&quot;,&quot;,&quot;,&quot;Michelle&quot;,&quot;Obama&quot;,&quot;,&quot;,&quot;have&quot;,&quot;released&quot;,&quot;eight&quot;,&quot;years&quot;,&quot;of&quot;,&quot;joint&quot;,&quot;returns&quot;,&quot;.&quot;],&quot;ner_tags&quot;:[&quot;O&quot;,&quot;PERSON&quot;,&quot;PERSON&quot;,&quot;O&quot;,&quot;O&quot;,&quot;O&quot;,&quot;O&quot;,&quot;PERSON&quot;,&quot;PERSON&quot;,&quot;O&quot;,&quot;O&quot;,&quot;O&quot;,&quot;DURATION&quot;,&quot;DURATION&quot;,&quot;O&quot;,&quot;O&quot;,&quot;O&quot;,&quot;O&quot;]}
</code></pre></div>
<p><strong>Output:</strong> rows in <code>people_mentions</code> table, e.g.:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{&quot;mention_id&quot;: &quot;118238@10_1&quot;, &quot;text&quot;: &quot;Barack Obama&quot;, &quot;sentence_id&quot;: &quot;118238@10&quot;, &quot;start_position&quot;: 1, &quot;length&quot;: 2}
{&quot;mention_id&quot;: &quot;118238@10_7&quot;, &quot;text&quot;: &quot;Michelle Obama&quot;, &quot;sentence_id&quot;: &quot;118238@10&quot;, &quot;start_position&quot;: 7, &quot;length&quot;: 2}
</code></pre></div>
<p>This first extractor will extract people mentions (In the sample data, &quot;Barack Obama&quot; and &quot;Michelle Obama&quot;) from the sentences, and put them into a new table. 
Note that we have named entity tags in column <code>ner_tags</code> of our <code>sentences</code> table. We will use this column to identify people mentions: we assume that <em>a word phrase is a people mention if all its words are tagged as <code>PERSON</code> in its <code>ner_tags</code> field.</em></p>

<!-- Ideally you would want to add your own domain-specific features to extract mentions. For example, people names are usually capitalized, tagged with a noun phrase part of speech tag, and have certain dependency paths to other words in the sentence. However, because the Stanford NLP Parser is relatively good at identifying people and tags them with a `PERSON` named-entity tag we trust its output and don't make the predictions ourselves. We simply assume that all people identified by the NLP Parser are correct. Note that this assumption is not ideal and usually does not work for other types of entities, but it is good enough to build a first version of our application.
 -->

<p>Let&#39;s create our first extractors in DeepDive, by adding several lines into <code>deepdive.extraction.extractors</code> block in <code>application.conf</code>, which should be present in the template:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">deepdive <span class="o">{</span>
  ...
  <span class="c"># Put your extractors here</span>
  extraction.extractors <span class="o">{</span>

    <span class="c"># Extractor 1: Clean output tables of all extractors</span>
    ext_clear_table <span class="o">{</span>
      style: <span class="s2">&quot;sql_extractor&quot;</span>
      sql: <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        DELETE FROM people_mentions;</span>
<span class="s2">        DELETE FROM has_spouse;</span>
<span class="s2">        DELETE FROM has_spouse_features;</span>
<span class="s2">        &quot;&quot;&quot;</span>
    <span class="o">}</span>

    <span class="c"># Extractor 2: extract people mentions:</span>
    ext_people <span class="o">{</span>
      <span class="c"># An input to the extractor is a row (tuple) of the following query:</span>
      input: <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">        SELECT  sentence_id, words, ner_tags</span>
<span class="s2">          FROM  sentences&quot;&quot;&quot;</span>

      <span class="c"># output of extractor will be written to this table:</span>
      output_relation: <span class="s2">&quot;people_mentions&quot;</span>

      <span class="c"># This user-defined function will be performed on each row (tuple) of input query:</span>
      udf: <span class="k">${</span><span class="nv">APP_HOME</span><span class="k">}</span><span class="s2">&quot;/udf/ext_people.py&quot;</span>

      dependencies: <span class="o">[</span><span class="s2">&quot;ext_clear_table&quot;</span><span class="o">]</span>
    <span class="o">}</span>
    <span class="c"># ... (more extractors to add here)</span>
  <span class="o">}</span> 
  ...   
<span class="o">}</span>
</code></pre></div>
<p>Note that we first create an extractor <code>ext_clear_table</code> to be executed
before any other extractor, to clear output tables of all other
extractors. This is a <code>sql_extractor</code>, which is just a set of SQL
commands specified in <code>sql</code> field.</p>

<p>For our person mention extractor <code>ext_people</code>, let&#39;s go through each line:</p>

<ol>
<li>The input to the <code>ext_people</code> extractor are all sentences (identifiers, words and named entity tags), selected using a SQL statement.</li>
<li>The output of the extractor will be written to the <code>people_mentions</code> table. (for the table format, refer to the <a href="#table_cheatsheet">cheat-sheet</a> in appendix.)</li>
<li>The extractor script is <code>udf/ext_people.py</code>. DeepDive will execute this command and stream input to the <em>stdin</em> of the process, and read output from <em>stdout</em> of the process.</li>
<li>The <code>dependencies</code> field specifies that this extractor can be executed only after <code>ext_clear_table</code> extractor finishes.</li>
</ol>

<p>There are other ways you can use an extractor, refer to the <a href="extractors.html">extractor guide</a> for a more comprehensive list. </p>

<p>We create a folder named <code>udf</code> to put our scripts:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">mkdir udf
</code></pre></div>
<p>Then create a <code>udf/ext_people.py</code> script as the UDF for this extractor, which scan through input sentences and output phrases. The script can be written as follows:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c">#! /usr/bin/env python</span>
<span class="c"># File: udf/ext_people.py</span>

<span class="kn">import</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">sys</span>

<span class="c"># For-loop for each row in the input query</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
  <span class="c"># load JSON format of the current tuple</span>
  <span class="n">sentence_obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
  <span class="c"># Find phrases that are continuous words tagged with PERSON.</span>
  <span class="n">phrases</span> <span class="o">=</span> <span class="p">[]</span>   <span class="c"># Store (start_position, length, text)</span>
  <span class="n">words</span> <span class="o">=</span> <span class="n">sentence_obj</span><span class="p">[</span><span class="s">&quot;words&quot;</span><span class="p">]</span>         <span class="c"># a list of all words</span>
  <span class="n">ner_tags</span> <span class="o">=</span> <span class="n">sentence_obj</span><span class="p">[</span><span class="s">&quot;ner_tags&quot;</span><span class="p">]</span>   <span class="c"># ner_tags for each word</span>
  <span class="n">start_index</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="k">while</span> <span class="n">start_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">):</span>
    <span class="c"># Checking if there is a PERSON phrase starting from start_index</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">start_index</span>
    <span class="k">while</span> <span class="n">index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="ow">and</span> <span class="n">ner_tags</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">==</span> <span class="s">&quot;PERSON&quot;</span><span class="p">:</span> 
      <span class="n">index</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">index</span> <span class="o">!=</span> <span class="n">start_index</span><span class="p">:</span>   <span class="c"># found a person from &quot;start_index&quot; to &quot;index&quot;</span>
      <span class="n">text</span> <span class="o">=</span> <span class="s">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">words</span><span class="p">[</span><span class="n">start_index</span><span class="p">:</span><span class="n">index</span><span class="p">])</span>
      <span class="n">length</span> <span class="o">=</span> <span class="n">index</span> <span class="o">-</span> <span class="n">start_index</span>
      <span class="n">phrases</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">start_index</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">text</span><span class="p">))</span>
    <span class="n">start_index</span> <span class="o">=</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span>

  <span class="c"># Output a tuple for each PERSON phrase</span>
  <span class="k">for</span> <span class="n">start_position</span><span class="p">,</span> <span class="n">length</span><span class="p">,</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">phrases</span><span class="p">:</span>
    <span class="k">print</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
      <span class="s">&quot;sentence_id&quot;</span><span class="p">:</span> <span class="n">sentence_obj</span><span class="p">[</span><span class="s">&quot;sentence_id&quot;</span><span class="p">],</span>
      <span class="s">&quot;start_position&quot;</span><span class="p">:</span> <span class="n">start_position</span><span class="p">,</span>
      <span class="s">&quot;length&quot;</span><span class="p">:</span> <span class="n">length</span><span class="p">,</span>
      <span class="s">&quot;text&quot;</span><span class="p">:</span> <span class="n">text</span><span class="p">,</span>
      <span class="c"># Create an unique mention_id by sentence_id + offset:</span>
      <span class="s">&quot;mention_id&quot;</span><span class="p">:</span> <span class="s">&#39;</span><span class="si">%s</span><span class="s">_</span><span class="si">%d</span><span class="s">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">sentence_obj</span><span class="p">[</span><span class="s">&quot;sentence_id&quot;</span><span class="p">],</span> <span class="n">start_position</span><span class="p">)</span>
    <span class="p">})</span>
</code></pre></div>
<p>If you want to get a sample of the inputs to th extractor, refer to <a href="walkthrough-extras.html#debug_extractors">getting example inputs</a> section in the Extras.</p>

<p>This <code>udf/ext_people.py</code> Python script takes sentences records as an input, and outputs a people record for each (potentially multi-word) person phrase found in the sentence, which are one or multiple continuous words tagged with <code>PERSON</code>.</p>

<p>Note that if you wanted to add debug output, you can print to <em>stderr</em> instead of stdout, and the messages would appear on the terminal, as well as in the log file (<code>$DEEPDIVE_HOME/log/DATE_TIME.txt</code>).</p>

<p>You can now run your extractor by executing <code>./run.sh</code>, and you will be able to see extracted results in <code>people_mentions</code> table. We select the results of the sample input data to see what happens in the extractor.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">./run.sh    <span class="c"># Run extractors now</span>
psql -d deepdive_spouse -c <span class="s2">&quot;select * from people_mentions where sentence_id=&#39;118238@10&#39;&quot;</span>
</code></pre></div>
<p>Results are:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"> sentence_id | start_position | length |      text      | mention_id
-------------+----------------+--------+----------------+-------------
 118238@10   |              1 |      2 | Barack Obama   | 118238@10_1
 118238@10   |              7 |      2 | Michelle Obama | 118238@10_7
(2 rows)
</code></pre></div>
<p>To double-check your results are correct, count number of tuples in your table:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">psql -d deepdive_spouse -c <span class="s2">&quot;select count(*) from sentences;&quot;</span>
psql -d deepdive_spouse -c <span class="s2">&quot;select count(*) from people_mentions;&quot;</span>
</code></pre></div>
<p>Results are:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"> count
-------
 43789

 count
-------
 39266
</code></pre></div>
<p><a id="candidate_relations" href="#"> </a></p>

<h4>Extracting candidate relations between mention pairs</h4>

<p>Now we need to identify candidates for the <code>has_spouse</code> relation. For simplicity, we only extract each <strong>pair of person mentions in the same sentence</strong> as a relation candidate. </p>

<p>To train our system to decide whether these candidates are correct relations, we also need to generate training data. However, it is hard to find ground truth on whether two mentions participate in <code>has_spouse</code> relation. We use <a href="general/relation_extraction.html">distant supervision</a> that generate mention-level training data by heuristically mapping them to known entity-level relations in an existing knowledge base.</p>

<p>This extractor will take all mentions of people from a same sentence, and put each pair of them into the table <code>has_spouse</code>, while generating true / false labels on some of the mention pairs.</p>

<p><strong>Input:</strong> two mentions from <code>people_mentions</code> table that comes from a same sentence. e.g.:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{&quot;p1_text&quot;:&quot;Michelle Obama&quot;,&quot;p1_mention_id&quot;:&quot;118238@10_7&quot;,&quot;p2_text&quot;:&quot;Barack Obama&quot;,&quot;p2_mention_id&quot;:&quot;118238@10_1&quot;,&quot;sentence_id&quot;:&quot;118238@10&quot;}
</code></pre></div>
<p><strong>Output:</strong> one row in <code>has_spouse</code> table:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{&quot;person1_id&quot;: &quot;118238@10_7&quot;, &quot;person2_id&quot;: &quot;118238@10_1&quot;, &quot;sentence_id&quot;: &quot;118238@10&quot;, &quot;relation_id&quot;: &quot;118238@10_7_118238@10_1&quot;, &quot;description&quot;: &quot;Michelle Obama-Barack Obama&quot;, &quot;is_true&quot;: true, &quot;id&quot;: null}
</code></pre></div>
<p>To understand how DeepDive works, we should notice that the <code>has_spouse</code> table has following format:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">     Table &quot;public.has_spouse&quot;
   Column    |  Type   | Modifiers
-------------+---------+-----------
 person1_id  | bigint  |            # first person&#39;s mention_id in people_mentions
 person2_id  | bigint  |            # second person&#39;s mention_id
 sentence_id | bigint  |            # which senence it appears
 description | text    |            # a description of this relation pair
 is_true     | boolean |            # whether this relation is correct
 relation_id | bigint  |            # unique identifier for has_spouse
 id          | bigint  |            # reserved for DeepDive
</code></pre></div>
<p>Note that in table <code>has_spouse</code>, there is a special <code>is_true</code> column. We need this column because we want DeepDive to predict how likely it is that a given entry in the table is correct. In other words, DeepDive will create a <a href="general/inference.html">random variable</a> for each instance of it. More concretely, each row in the <code>has_spouse</code> table will be assigned a random variable for its <code>is_true</code> column. </p>

<p>Also note that we must reserve another special column, <code>id bigint</code>, in any table containing variables like this one. For system to use, this column should be <strong>left blank, and not be used anywhere</strong>. We will further see syntax requirements in <em>inference rules</em> related to this <code>id</code> column.</p>

<p>Let&#39;s tell DeepDive to use the <code>is_true</code> column of table <code>has_spouse</code> for probabilistic inference, by adding it into <code>schema.variables</code> Block in <code>application.conf</code>:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">schema.variables {
  has_spouse.is_true: Boolean
}
</code></pre></div>
<p>Let&#39;s create an extractor that extracts all candidate relations and puts them into the above table. We call them <em>candidate relations</em> because we are not sure whether or not they are actually correct, that&#39;s for DeepDive to predict.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">extraction.extractors <span class="o">{</span>

  <span class="c"># ... (other extractors)</span>

  <span class="c"># Extractor 3: extract mention relation candidates</span>
  ext_has_spouse_candidates <span class="o">{</span>
    <span class="c"># Each input (p1, p2) is a pair of mentions</span>
    input: <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">      SELECT  sentences.sentence_id,</span>
<span class="s2">              p1.mention_id AS p1_mention_id,</span>
<span class="s2">              p1.text       AS p1_text,</span>
<span class="s2">              p2.mention_id AS p2_mention_id,</span>
<span class="s2">              p2.text       AS p2_text</span>
<span class="s2">       FROM   people_mentions p1,</span>
<span class="s2">              people_mentions p2,</span>
<span class="s2">              sentences</span>
<span class="s2">      WHERE   p1.sentence_id = p2.sentence_id</span>
<span class="s2">        AND   p1.sentence_id = sentences.sentence_id</span>
<span class="s2">        AND   p1.mention_id != p2.mention_id;</span>
<span class="s2">        &quot;&quot;&quot;</span>
    output_relation : <span class="s2">&quot;has_spouse&quot;</span>
    udf             : <span class="k">${</span><span class="nv">APP_HOME</span><span class="k">}</span><span class="s2">&quot;/udf/ext_has_spouse.py&quot;</span>

    <span class="c"># Run this extractor after &quot;ext_people&quot;</span>
    dependencies    : <span class="o">[</span><span class="s2">&quot;ext_people&quot;</span><span class="o">]</span>
  <span class="o">}</span>

<span class="o">}</span>
</code></pre></div>
<p>Note that this extractor must be executed after our last extractor <code>ext_people</code>, which is specified in &quot;dependencies&quot; field.</p>

<p>When generating relation candidates, we also generate training data using <a href="general/relation_extraction.html">distant supervision</a>. There are some pairs of people that we know for sure are married, and we can use them as training data for DeepDive. Similarly, if we know that two people are not married, we can use them as negative training examples. In our case we will be using data from <a href="http://www.freebase.com/">Freebase</a> for distant supervision, and use direct string match to map mentions to entities.</p>

<p>To generate positive examples, we have exported all pairs of people with a <code>has_spouse</code> relationship from the <a href="https://developers.google.com/freebase/data">Freebase data dump</a> and included them in a CSV file <code>data/spouses.csv</code>.</p>

<p>To generate negative examples, we use two heuristics:</p>

<ol>
<li><p>A pair of the same person is a negative example of <code>has_spouse</code> relations, e.g., &quot;Barack Obama&quot; cannot be married to &quot;Barack Obama&quot;. </p></li>
<li><p>A pairs of some relations incompatible with <code>has_spouse</code> can be treated as a negative example, e.g. if A is B&#39;s parent / children / sibling, A is not likely to be married to B.  We include a TSV file in <code>data/non-spouses.tsv</code> containing such relations sampled from Freebase.</p></li>
</ol>

<p>Let&#39;s create a script <code>udf/ext_has_spouse.py</code> as below, to generate and label the relation candidates:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c">#! /usr/bin/env python</span>
<span class="c"># File: udf/ext_has_spouse.py</span>

<span class="kn">import</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">csv</span><span class="o">,</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="n">BASE_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">realpath</span><span class="p">(</span><span class="n">__file__</span><span class="p">))</span>

<span class="c"># Load the spouse dictionary for distant supervision</span>
<span class="n">spouses</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c"># One person may have multiple spouses, so use set</span>
<span class="k">with</span> <span class="nb">open</span> <span class="p">(</span><span class="n">BASE_DIR</span> <span class="o">+</span> <span class="s">&quot;/../data/spouses.csv&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
  <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
    <span class="n">name1</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">name2</span> <span class="o">=</span> <span class="n">line</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">spouses</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">name1</span><span class="p">,</span> <span class="n">name2</span><span class="p">))</span>
    <span class="n">spouses</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">name2</span><span class="p">,</span> <span class="n">name1</span><span class="p">))</span>

<span class="c"># Load relations of people that are not spouse</span>
<span class="n">non_spouses</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">BASE_DIR</span> <span class="o">+</span> <span class="s">&#39;/../data/non-spouses.tsv&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
  <span class="n">name1</span><span class="p">,</span> <span class="n">name2</span><span class="p">,</span> <span class="n">relation</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
  <span class="n">non_spouses</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">name1</span><span class="p">,</span> <span class="n">name2</span><span class="p">))</span>  <span class="c"># Add a non-spouse relation pair</span>
  <span class="n">non_spouses</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">name2</span><span class="p">,</span> <span class="n">name1</span><span class="p">))</span>

<span class="c"># For each input tuple</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
  <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
  <span class="n">p1_text</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;p1_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
  <span class="n">p2_text</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;p2_text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
  <span class="n">p1_lower</span> <span class="o">=</span> <span class="n">p1_text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
  <span class="n">p2_lower</span> <span class="o">=</span> <span class="n">p2_text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

  <span class="n">is_true</span> <span class="o">=</span> <span class="bp">None</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">p1_lower</span><span class="p">,</span> <span class="n">p2_lower</span><span class="p">)</span> <span class="ow">in</span> <span class="n">spouses</span><span class="p">:</span>
    <span class="n">is_true</span> <span class="o">=</span> <span class="bp">True</span>    <span class="c"># the mention pair is in our supervision dictionary</span>
  <span class="k">elif</span> <span class="p">(</span><span class="n">p1_lower</span><span class="p">,</span> <span class="n">p2_lower</span><span class="p">)</span> <span class="ow">in</span> <span class="n">non_spouses</span><span class="p">:</span> 
    <span class="n">is_true</span> <span class="o">=</span> <span class="bp">False</span>   <span class="c"># they appear in other relations</span>
  <span class="k">elif</span> <span class="p">(</span><span class="n">p1_text</span> <span class="o">==</span> <span class="n">p2_text</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">p1_text</span> <span class="ow">in</span> <span class="n">p2_text</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">p2_text</span> <span class="ow">in</span> <span class="n">p1_text</span><span class="p">):</span>
    <span class="n">is_true</span> <span class="o">=</span> <span class="bp">False</span>   <span class="c"># they are the same person</span>

  <span class="c"># Create an unique relation_id by a combination of two mention&#39;s IDs</span>
  <span class="n">relation_id</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;p1_mention_id&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="s">&#39;_&#39;</span> <span class="o">+</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;p2_mention_id&quot;</span><span class="p">]</span>

  <span class="k">print</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span><span class="s">&quot;person1_id&quot;</span><span class="p">:</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;p1_mention_id&quot;</span><span class="p">],</span>  <span class="s">&quot;person2_id&quot;</span><span class="p">:</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;p2_mention_id&quot;</span><span class="p">],</span>
    <span class="s">&quot;sentence_id&quot;</span><span class="p">:</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;sentence_id&quot;</span><span class="p">],</span>  <span class="s">&quot;description&quot;</span><span class="p">:</span> <span class="s">&quot;</span><span class="si">%s</span><span class="s">-</span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">p1_text</span><span class="p">,</span> <span class="n">p2_text</span><span class="p">),</span>
    <span class="s">&quot;is_true&quot;</span><span class="p">:</span> <span class="n">is_true</span><span class="p">,</span>  <span class="s">&quot;relation_id&quot;</span><span class="p">:</span> <span class="n">relation_id</span><span class="p">,</span>  <span class="s">&quot;id&quot;</span><span class="p">:</span> <span class="bp">None</span>
  <span class="p">})</span>
</code></pre></div>
<p>Now if you like, you can run the system by executing <code>run.sh</code> and check the output relation <code>has_spouse</code>. <code>run.sh</code> will run the full pipeline with both extractors <code>ext_people</code> and <code>ext_has_spouse</code>. If you only want to run your new extractor, refer to the <a href="walkthrough-extras.html#pipelines">Pipeline section in Extras</a>.</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">./run.sh
psql -d deepdive_spouse -c <span class="s2">&quot;select * from has_spouse where person1_id=&#39;118238@10_7&#39;&quot;</span>
</code></pre></div>
<p>Results look like:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"> person1_id  | person2_id  | sentence_id |         description         | is_true |       relation_id       | id
-------------+-------------+-------------+-----------------------------+---------+-------------------------+----
 118238@10_1 | 118238@10_7 | 118238@10   | Barack Obama-Michelle Obama | t       | 118238@10_1_118238@10_7 |
</code></pre></div>
<p>To check your results are correct, count number of tuples in your table:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">psql -d deepdive_spouse -c <span class="s2">&quot;select is_true, count(*) from has_spouse group by is_true;&quot;</span>
</code></pre></div>
<p>Results are:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"> is_true | count
---------+-------
 f       |  3770
 t       |  2234
         | 69418
</code></pre></div>
<p><a id="candidate_relation_features" href="#"> </a></p>

<h4>Adding Features for candidate relations</h4>

<p>For DeepDive to make predictions, we need to add <em>features</em> to our candidate relations. Features are properties that help decide whether or not the given relation is correct. We use standard machine learning features, but this will result in low quality which we will improve later. We will write an extractor that extracts features from mention pairs and the sentences they come from.</p>

<p>Currently we use features include: (1) a bag of words between the two mentions; (2) the number of words between two phases; (3) whether the last word of two person&#39;s names (last name) are the same.
We will refine these features later in the section of <a href="#improve">improve the results</a>.</p>

<p><strong>Input:</strong> a mention pair as well as all words in the sentence it appears. e.g.:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{&quot;p2_length&quot;:2,&quot;p1_length&quot;:2,&quot;words&quot;:[&quot;Sen.&quot;,&quot;Barack&quot;,&quot;Obama&quot;,&quot;and&quot;,&quot;his&quot;,&quot;wife&quot;,&quot;,&quot;,&quot;Michelle&quot;,&quot;Obama&quot;,&quot;,&quot;,&quot;have&quot;,&quot;released&quot;,&quot;eight&quot;,&quot;years&quot;,&quot;of&quot;,&quot;joint&quot;,&quot;returns&quot;,&quot;.&quot;],&quot;relation_id&quot;:&quot;118238@10_1_118238@10_7&quot;,&quot;p1_start&quot;:1,&quot;p2_start&quot;:7}
</code></pre></div>
<p><strong>Output:</strong> all features for this mention pair described above:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">{&quot;relation_id&quot;: &quot;118238@10_1_118238@10_7&quot;, &quot;feature&quot;: &quot;word_between=,&quot;}
{&quot;relation_id&quot;: &quot;118238@10_1_118238@10_7&quot;, &quot;feature&quot;: &quot;word_between=his&quot;}
{&quot;relation_id&quot;: &quot;118238@10_1_118238@10_7&quot;, &quot;feature&quot;: &quot;potential_last_name_match&quot;}
{&quot;relation_id&quot;: &quot;118238@10_1_118238@10_7&quot;, &quot;feature&quot;: &quot;word_between=wife&quot;}
{&quot;relation_id&quot;: &quot;118238@10_1_118238@10_7&quot;, &quot;feature&quot;: &quot;num_words_between=4&quot;}
{&quot;relation_id&quot;: &quot;118238@10_1_118238@10_7&quot;, &quot;feature&quot;: &quot;word_between=and&quot;}
</code></pre></div>
<p>Create a new extractor for features, which will execute after our last <code>ext_has_spouse_candidates</code> extractor:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">extraction.extractors <span class="o">{</span>

  <span class="c"># ... (other extractors)</span>

  <span class="c"># Extractor 4: extract features for relation candidates</span>
  ext_has_spouse_features <span class="o">{</span>
    input: <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">      SELECT  sentences.words,</span>
<span class="s2">              has_spouse.relation_id,</span>
<span class="s2">              p1.start_position  AS  p1_start,</span>
<span class="s2">              p1.length          AS  p1_length,</span>
<span class="s2">              p2.start_position  AS  p2_start,</span>
<span class="s2">              p2.length          AS  p2_length</span>
<span class="s2">        FROM  has_spouse,</span>
<span class="s2">              people_mentions p1,</span>
<span class="s2">              people_mentions p2,</span>
<span class="s2">              sentences</span>
<span class="s2">       WHERE  has_spouse.person1_id = p1.mention_id</span>
<span class="s2">         AND  has_spouse.person2_id = p2.mention_id</span>
<span class="s2">         AND  has_spouse.sentence_id = sentences.sentence_id;</span>
<span class="s2">         &quot;&quot;&quot;</span>
    output_relation : <span class="s2">&quot;has_spouse_features&quot;</span>
    udf             : <span class="k">${</span><span class="nv">APP_HOME</span><span class="k">}</span><span class="s2">&quot;/udf/ext_has_spouse_features.py&quot;</span>
    dependencies    : <span class="o">[</span><span class="s2">&quot;ext_has_spouse_candidates&quot;</span><span class="o">]</span>
  <span class="o">}</span>

<span class="o">}</span>
</code></pre></div>
<p>To create our extractor UDF, we will make use of <code>ddlib</code>, our python library that provides useful utilities such as <code>Span</code> to manipulate elements in sentences. Make sure you followed the <a href="installation.html#ddlib">installation guide</a> to properly use <code>ddlib</code>.</p>

<p>Create script <code>udf/ext_has_spouse_features.py</code> as follows:</p>
<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c">#! /usr/bin/env python</span>
<span class="c"># File: udf/ext_has_spouse_features.py</span>

<span class="kn">import</span> <span class="nn">sys</span><span class="o">,</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">ddlib</span>     <span class="c"># DeepDive python utility</span>

<span class="c"># For each input tuple</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdin</span><span class="p">:</span>
  <span class="n">obj</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
  <span class="n">words</span> <span class="o">=</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;words&quot;</span><span class="p">]</span>
  <span class="c"># Unpack input into tuples.</span>
  <span class="n">span1</span> <span class="o">=</span> <span class="n">ddlib</span><span class="o">.</span><span class="n">Span</span><span class="p">(</span><span class="n">begin_word_id</span><span class="o">=</span><span class="n">obj</span><span class="p">[</span><span class="s">&#39;p1_start&#39;</span><span class="p">],</span> <span class="n">length</span><span class="o">=</span><span class="n">obj</span><span class="p">[</span><span class="s">&#39;p1_length&#39;</span><span class="p">])</span>
  <span class="n">span2</span> <span class="o">=</span> <span class="n">ddlib</span><span class="o">.</span><span class="n">Span</span><span class="p">(</span><span class="n">begin_word_id</span><span class="o">=</span><span class="n">obj</span><span class="p">[</span><span class="s">&#39;p2_start&#39;</span><span class="p">],</span> <span class="n">length</span><span class="o">=</span><span class="n">obj</span><span class="p">[</span><span class="s">&#39;p2_length&#39;</span><span class="p">])</span>

  <span class="c"># Features for this pair come in here</span>
  <span class="n">features</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

  <span class="c"># Feature 1: Bag of words between the two phrases</span>
  <span class="n">words_between</span> <span class="o">=</span> <span class="n">ddlib</span><span class="o">.</span><span class="n">tokens_between_spans</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">span1</span><span class="p">,</span> <span class="n">span2</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words_between</span><span class="o">.</span><span class="n">elements</span><span class="p">:</span>
    <span class="n">features</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;word_between=&quot;</span> <span class="o">+</span> <span class="n">word</span><span class="p">)</span>

  <span class="c"># Feature 2: Number of words between the two phrases</span>
  <span class="n">features</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;num_words_between=</span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">words_between</span><span class="o">.</span><span class="n">elements</span><span class="p">))</span>

  <span class="c"># Feature 3: Does the last word (last name) match?</span>
  <span class="n">last_word_left</span> <span class="o">=</span> <span class="n">ddlib</span><span class="o">.</span><span class="n">materialize_span</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">span1</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">last_word_right</span> <span class="o">=</span> <span class="n">ddlib</span><span class="o">.</span><span class="n">materialize_span</span><span class="p">(</span><span class="n">words</span><span class="p">,</span> <span class="n">span2</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">if</span> <span class="p">(</span><span class="n">last_word_left</span> <span class="o">==</span> <span class="n">last_word_right</span><span class="p">):</span>
    <span class="n">features</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s">&quot;potential_last_name_match&quot;</span><span class="p">)</span>

  <span class="c"># # Use this line if you want to print out all features extracted:</span>
  <span class="c"># ddlib.log(features)</span>

  <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">:</span>  
    <span class="k">print</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
      <span class="s">&quot;relation_id&quot;</span><span class="p">:</span> <span class="n">obj</span><span class="p">[</span><span class="s">&quot;relation_id&quot;</span><span class="p">],</span>
      <span class="s">&quot;feature&quot;</span><span class="p">:</span> <span class="n">feature</span>
    <span class="p">})</span>
</code></pre></div>
<p>Same as before, you can run the system by executing <code>run.sh</code> and check the output relation <code>has_spouse_features</code>. (If you only want to run your new extractor, refer to the <a href="walkthrough-extras.html#pipelines">Pipeline section in Extras</a>.)</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">./run.sh
psql -d deepdive_spouse -c <span class="s2">&quot;select * from has_spouse_features where relation_id = &#39;118238@10_1_118238@10_7&#39;&quot;</span>
</code></pre></div>
<p>Results look like:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">       relation_id       |          feature
-------------------------+---------------------------
 118238@10_1_118238@10_7 | word_between=,
 118238@10_1_118238@10_7 | word_between=his
 118238@10_1_118238@10_7 | potential_last_name_match
 118238@10_1_118238@10_7 | word_between=wife
 118238@10_1_118238@10_7 | num_words_between=4
 118238@10_1_118238@10_7 | word_between=and
(6 rows)
</code></pre></div>
<p>Again, count number of tuples in your table:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">psql -d deepdive_spouse -c <span class="s2">&quot;select count(*) from has_spouse_features;&quot;</span>
</code></pre></div>
<p>Results are:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">  count
---------
 1160450
</code></pre></div>
<p><a id="inference_rules" href="#"> </a></p>

<h3>Writing inference rules</h3>

<p>Now we need to tell DeepDive how to generate <a href="general/inference.html">factor graphs</a> to perform probabilistic inference.  We want to predict the <code>is_true</code> column of the <code>has_spouse</code> table based on the features we have extracted, by assigning each feature a weight that DeepDive will learn. This is the simplest rule you can write, because it does not involve domain knowledge or relationships among variables. </p>

<p>Add the following lines to your <code>application.conf</code>, into <code>inference.factors</code> block:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c"># Put your inference rules here</span>
inference.factors <span class="o">{</span>

  <span class="c"># A simple logistic regression rule</span>
  f_has_spouse_features <span class="o">{</span>

    <span class="c"># input to the inference rule is all the has_spouse candidate relations,</span>
    <span class="c">#   as well as the features connected to them:</span>
    input_query: <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">      SELECT has_spouse.id      AS &quot;</span>has_spouse.id<span class="s2">&quot;,</span>
<span class="s2">             has_spouse.is_true AS &quot;</span>has_spouse.is_true<span class="s2">&quot;,</span>
<span class="s2">             feature</span>
<span class="s2">      FROM has_spouse,</span>
<span class="s2">           has_spouse_features</span>
<span class="s2">      WHERE has_spouse_features.relation_id = has_spouse.relation_id</span>
<span class="s2">      &quot;&quot;&quot;</span>

    <span class="c"># Factor function:</span>
    <span class="k">function</span> : <span class="s2">&quot;IsTrue(has_spouse.is_true)&quot;</span>

    <span class="c"># Weight of the factor is decided by the value of &quot;feature&quot; column in input query</span>
    weight   : <span class="s2">&quot;?(feature)&quot;</span>
  <span class="o">}</span>

  <span class="c"># ... (other inference rules)</span>
<span class="o">}</span>
</code></pre></div>
<p>This rule generates a model similar to a logistic regression classifier. We use a set of features to make a prediction about the variable we care about. For each row in the <em>input query</em> we are adding a <a href="general/inference.html">factor</a> that connects to the <code>has_spouse.is_true</code> variable with a different weight for each feature name. </p>

<p>Note that the syntax requires users to <strong>explicitly select</strong> in <code>input_query</code>:</p>

<ol>
<li><code>id</code> column for each variable</li>
<li>The variable column, which is <code>is_true</code> in this case</li>
<li>The column weight is dependent on, which is <code>feature</code> in this case</li>
</ol>

<p>And when selecting them, users must explicitly alias <code>id</code> to <code>[relation_name].id</code> and <code>[variable]</code> to <code>[relation_name].[variable]</code> for system to use. See more in <a href="inference_rules.html">inference rule guide</a>.</p>

<p><a id="learning_inference" href="#"> </a></p>

<h3>Statistical inference and learning</h3>

<p>Now that we have inference rules specified, DeepDive will automatically ground the factor graph with these rules, then perform learning to figure out the weights, and do inference to compute probabilities of candidate relations.</p>

<p>We are almost ready to run! In order to evaluate our results, we also want to define a <em>holdout fraction</em> for our predictions. The holdout fraction defines how much of our training data we want to treat as testing data used to compare our predictions against. By default the holdout fraction is <code>0</code>, which means that we cannot evaluate the precision of our results. Add the following line to holdout 1/4 of the training data. Modify <code>application.conf</code> with a holdout fraction:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"># Specify a holdout fraction
calibration.holdout_fraction: 0.25
</code></pre></div>
<p><a id="get_result" href="#"> </a></p>

<h3>Get and Check results</h3>

<p>Let&#39;s try running the full pipeline using <code>./run.sh</code>. (If you want to run part of the pipeline, refer to <a href="walkthrough-extras.html#pipelines">pipeline section</a>)</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">./run.sh
</code></pre></div>
<p>After running, you should see a summary report similar to:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">16:51:37 [profiler] INFO  --------------------------------------------------
16:51:37 [profiler] INFO  Summary Report
16:51:37 [profiler] INFO  --------------------------------------------------
16:51:37 [profiler] INFO  ext_clear_table SUCCESS [330 ms]
16:51:37 [profiler] INFO  ext_people SUCCESS [40792 ms]
16:51:37 [profiler] INFO  ext_has_spouse_candidates SUCCESS [17194 ms]
16:51:37 [profiler] INFO  ext_has_spouse_features SUCCESS [189242 ms]
16:51:37 [profiler] INFO  inference_grounding SUCCESS [3881 ms]
16:51:37 [profiler] INFO  inference SUCCESS [13366 ms]
16:51:37 [profiler] INFO  calibration plot written to /YOUR/PATH/TO/deepdive/out/TIME/calibration/has_spouse.is_true.png [0 ms]
16:51:37 [profiler] INFO  calibration SUCCESS [920 ms]
16:51:37 [profiler] INFO  --------------------------------------------------
</code></pre></div>
<p>Great, let&#39;s take a look at some of the predictions that DeepDive has made. DeepDive creates a view <code>has_spouse_is_true_inference</code> for each variable you have defined in the database. Type in following query in command line to sample some high-confidence mention-level relations and the sentences they come from:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">psql -d deepdive_spouse -c <span class="s2">&quot;</span>
<span class="s2">  SELECT s.sentence_id, description, is_true, expectation, s.sentence</span>
<span class="s2">  FROM has_spouse_is_true_inference hsi, sentences s</span>
<span class="s2">  WHERE s.sentence_id = hsi.sentence_id and expectation &gt; 0.9</span>
<span class="s2">  ORDER BY random() LIMIT 5;</span>
<span class="s2">&quot;</span>
</code></pre></div>
<p>The result should be something like (might not be the same):</p>
<div class="highlight"><pre><code class="language-text" data-lang="text"> sentence_id |       description        | is_true | expectation | sentence
-------------+--------------------------+---------+-------------+----------
 154431@0    | Al Austin-Akshay Desai   |         |       0.972 | Guest list Jeff Atwater , Senate president Al Austin , Republican fundraiser from Tampa St. Petersburg Mayor Rick Ba
ker and wife , Joyce , St. Petersburg Brian Ballard , former chief of staff for Gov. Bob Martinez and a campaign adviser to Crist Rodney Barreto , a Crist fundraiser Ron Book , South
 Florida lobbyist Charlie Bronson , agriculture commissioner Dean Colson , a Miami lawyer and adviser to the governor on higher education issues Dr. Akshay Desai , head of Universal
Health Care Insurance in St. Petersburg Eric Eikenberg , Crist &#39;s chief of staff Fazal Fazlin , entrepreneur -LRB- held fundraisers for Crist during the gubernatorial campaign -RRB-
, St. Petersburg .
 148797@53   | Michael-Carole Shelley   |         |       0.954 | WITH : Haydn Gwynne -LRB- Mrs. Wilkinson -RRB- , Gregory Jbara -LRB- Dad -RRB- , Carole Shelley -LRB- Grandma -RRB-
and Santino Fontana -LRB- Tony -RRB- , David Bologna and Frank Dolce -LRB- Michael -RRB- , and David Alvarez , Trent Kowalik and Kiril Kulish -LRB- Billy -RRB- .
 58364@10    | John-Jack Edwards        |         |       0.944 | This year , John and Jack Edwards are far from the only parent and child negotiating the awkward intersection of fam
ily and campaign life .
 40427@30    | James Taylor-Carly Simon |         |       0.962 | Look at James Taylor and Carly Simon , Whitney Houston and Bobby Brown or Britney Spears and Kevin Federline -LRB- y
es , calling him a musician is a stretch -RRB- .
 23278@18    | Chazz-Josh Gordon        |         |       0.944 | Directors Josh Gordon and Will Speck even discover an original way of hitting Chazz and Jimmy below the belt simulta
neously .
(5 rows)
</code></pre></div>
<!-- The result should be something like (might not be the same):

     sentence_id |             description             | expectation
    -------------+-------------------------------------+-------------
           77558 | Calvin Coolidge-Grace Coolidge      |           1
           84350 | Cherie Blair-Tony Blair             |           1
           64209 | Cecilia-Sarkozy                     |           1
           84337 | Tony Blair-Cherie Blair             |           1
           70974 | Dustin Hoffman-Natalie Portman      |       0.998
           67407 | Dustin Hoffman-Dennis Quaid         |       0.998
           52334 | Mary Matalin-James Carville         |       0.998
           78704 | Bill Clinton-Hillary Rodham Clinton |       0.998
           48282 | Clinton-Obama                       |       0.998
           47994 | Lauren Bacall-Jason Robards         |       0.998
    (10 rows)
 -->

<p>We might see that the results are actually pretty bad. Let&#39;s discuss how to examine the results.</p>

<!-- can see that some of these tuples are actually correct instances of married people. (Among above results, row 1, 2, 7, 8, 10 are correct) -->

<p>There are several common methods in DeepDive to examine results. DeepDive generates <a href="general/calibration.html">calibration plots</a> for all variables defined in the schema to help with debugging. Let&#39;s take a look at the generated calibration plot, written to the file outputted in the summary report above (has<em>spouse.is</em>true.png). It should look something like this:</p>

<p><img src="http://deepdive.stanford.edu/assets/walkthrough_has_spouse_is_true.png" alt="Calibration"></p>

<p>The calibration plot contains useful information that help you to improve the quality of your predictions. For actionable advice about interpreting calibration plots, refer to the <a href="general/calibration.html">calibration guide</a>. </p>

<p>Often, it is also useful to look at the <em>weights</em> that were learned for features or rules. You can do this by looking at the <code>mapped_inference_results_weights</code> table in the database. Type in following command to select features with highest weight (positive features):</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">psql -d deepdive_spouse -c <span class="s2">&quot;</span>
<span class="s2">  SELECT description, weight</span>
<span class="s2">  FROM dd_inference_result_variables_mapped_weights</span>
<span class="s2">  ORDER BY weight DESC</span>
<span class="s2">  LIMIT 5;</span>
<span class="s2">&quot;</span>
</code></pre></div>
<p>Results:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">                description                 |      weight
--------------------------------------------+------------------
 f_has_spouse_features-word_between=D-N.Y.  |  4.7886491287239
 f_has_spouse_features-word_between=married | 3.89640480091833
 f_has_spouse_features-word_between=wife    | 3.20275846390644
 f_has_spouse_features-word_between=widower | 3.18555507726798
 f_has_spouse_features-word_between=Sen.    | 2.91372149485723
(5 rows)
</code></pre></div>
<p>Type in following command to select top negative features:</p>
<div class="highlight"><pre><code class="language-bash" data-lang="bash">psql -d deepdive_spouse -c <span class="s2">&quot;</span>
<span class="s2">  SELECT description, weight</span>
<span class="s2">  FROM dd_inference_result_variables_mapped_weights</span>
<span class="s2">  ORDER BY weight ASC</span>
<span class="s2">  LIMIT 5;</span>
<span class="s2">&quot;</span>
</code></pre></div>
<p>Results:</p>
<div class="highlight"><pre><code class="language-text" data-lang="text">                   description                   |      weight
-------------------------------------------------+-------------------
 f_has_spouse_features-word_between=son          | -3.47510397136532
 f_has_spouse_features-word_between=grandson     | -3.30906093958107
 f_has_spouse_features-potential_last_name_match | -3.15563684816935
 f_has_spouse_features-word_between=Rodham       | -3.07171299387011
 f_has_spouse_features-word_between=addressing   | -2.89060819613259
</code></pre></div>
<p>Note that each execution may learn different weights, and these lists can look different. Generally, we might see that most weights make sense while some don&#39;t.</p>

<!-- You can further improve the prediction by different ways. There are many possible strategies including:

- Making use of co-reference information
- Performing entity linking instead of extraction relations among mentions in the text
- Adding more inference rules that encode your domain knowledge
- Adding more (or better) positive or negative training examples
- Adding more (or better) features

For the second point: our goal in this tutorial is get an initial
application up and running. There are a couple of problems with the
approach above which are worth drawing attention to: If two separate
sentences mention the fact that Barack Obama and Michelle Obama are in a
`has_spouse` relationship, then our approach does not know that they
refer to the same fact. In other words, we ignore the fact that "Barack
Obama" and "Michelle Obama" in both of these sentence refer to the same
entity in the real world. We also don't recognize *coreference* of two
mentions. That is, we don't know that "Barack Obama" and "Obama"
probably refer to the same person. 
 -->

<!-- We will address these issues in the [advanced part of the tutorial](walkthrough2.html). -->

<!-- Here we can see that the word phrase "and-former-President" in between the two person names has a rather high weight. This seems strange, since this phrase is not an indicator of a marriage relationship. One way to improve our predictions would be to add more negative evidence that would lower the weight of that feature.
 -->

<p>In the next section, we will discuss several ways to improve the results.</p>

<p><strong><a href="walkthrough-improve.html">Improving the results</a></strong></p>

            </div>
          </row>
        </div>
      </section>
    
      <footer id="footer">
        <div class="container">
          <row>
            <div class="col-md-10 col-md-offset-1">
              <p class="pull-left"> 
                Copyright, 2014 deepdive.stanford.edu
                
                <a href="mailto:contact.hazy@gmail.com">Questions? Email us</a>
              </p>
              <p class="pull-right"> 
                Visit DeepDive on <a href="https://github.com/hazyresearch/deepdive" target="_blank">Github</a> 
              </p>
            </div>
          </row>
        </div>
      </footer>

    
  
  </body>
</html>
