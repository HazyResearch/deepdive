# Overview

An important task of the modern era is to extract as much information as possible about the world and put it in a form that follows some concrete model (in other words, convert to structured form). One way to achieve this would be to process large amounts of text to identify what the text is talking about, and in what ways it relates those things. For example, we may want to put in structured form the fact that Barack Obama went to college at Columbia University, which may be expressed by the sentence "Barack Obama was a student at Columbia University."

# Entities

More abstractly, our task is to find in text the relationships between a finite set of conceptual objects that exist in the world. We call these conceptual objects entities. Usually a list of known entities exists: the entities can be contained in a large database of facts about the world such as Wikipedia (Wikipedia is a type of [knowledge base](http://en.wikipedia.org/wiki/Knowledge_base)), or can be manually constructed depending on the application (for example, the drugs that exist for treating a particular disease). For example, the entities Barack_Obama and Columbia_University are found in Wikipedia (but they could be part of a database that we ourselves generated). How can we associate these known entities with specific phrases in text?

# Entity Linking

In our example sentence "Barack Obama was a student at Columbia University," we can see with the human eye that the phrases Barack Obama and Columbia University represent the known entities Barack_Obama and Columbia_University. However, it is impossible to manually make this type of association for all the sentences we would like to analyze (for example, all the text on the web). Fortunately, we can teach computers how to do this automatically. The process of identifying phrases in sentences that refer to known entities is called entity linking. These phrases in text are called mentions, and the objective is to find (entity, mention) pairs such that the mention refers to the known entity. Note that entities in a knowledge base have types; most common entity types are person, location, and organization. As an example, entity linking would recognize that in sentence "Barack Obama was a student at Columbia University" the phrase "Barack Obama" refers to the person entity Barack_Obama and the phrase "Columbia University" refers to the university entity Columbia_University. Another way to say this is that the phrase "Barack Obama" is a mention for the entity Barack_Obama and the phrase "Columbia University" is a mention for the entity Columbia_University. In a more complicated example, entity linking would recognize that in the sentences "Barack Obama lives in the White House. Barack is the president of the U.S." the phrases "Barack Obama" and "Barack" are mentions of the same entity Barack_Obama.

# Relations

One way to structure information about the world is by creating relationships between entities of the form Alma_Mater(Barack_Obama, Columbia_University). Here, Alma_Mater is the relation which tells us how the entities Barack_Obama and Columbia_University are related.

# Relation Extraction

We are given an input sentence ("Barack Obama was a student at Columbia University"), and we have a database that contains the entities Barack_Obama and Columbia_University. We perform entity linking to know that the phrase "Barack Obama" is a mention for the entity Barack_Obama and the phrase "Columbia University" is a mention for the entity Columbia_University. Now, we want to use the input sentence to find what relationships, if any, exist between the mentions in the sentence. For this, we can apply the concept of relation extraction, which is the task of detecting relationships between objects in text documents. For example, given some some text corpus containing the sentence "Barack Obama was a student at Columbia University," we want to extract the relationship Alma_Mater(Barack_Obama, Columbia_University). 

# Target Relations

We must first have a target relation, which simply tells us what information we are looking for. Target relations define relationships between entity types in the form of Relationship(entity_type, entity_type), and can either be manually constructed or can come from existing knowledge bases such as Wikipedia, depending on the application. Wikipedia contains many examples of relationships in the right-hand info-box on certain pages; for example, a search for "Barack Obama" on Wikipedia tells us that one such relationship is Alma_Mater(person, university). This is the target relation for our example. 

# Training Data

So far we have not discussed any techniques for identifying the actual relationship in the sentence text. We can perform entity linking which allows us to see what entities are present in the sentence, but we have no way of identifying relationships between the entities in the correct way (as defined by the target relation). We need some way of determining what patterns in the sentence text correspond to what relationships. 

Ideally we would identify specific rules that would indicate that the sentence represents a particular relation; for example, we could say that any sentences that match the form "[person]'s Alma Mater is [university]" contain the relation Alma_Mater(person, university). For a sentence that we provide as input to this rule-based system, if the sentence is of this exact form the system will determine that the target relation holds, and through entity linking will be able to extract the entities involved in the relation. However, since sentences can be very different, there are multitudes of rules that could all be indicative of target relations in sentences. Therefore we need a smarter way of figuring out what rules, or text patterns, will indicate that certain relationships occur in a given sentence. Assuming that these patterns occur in written text (a reasonable assumption to make), the best way to find these patterns is to use machine learning: obtain a set of sentences such that the relationships between the entities they contain is known, and use this set of sentences as a training set to identify the patterns in text that indicate what relationship is contained in that text. In other words, provide the system with a set of sentences and the right answers (called labels) for them, and use machine learning to figure out how to get the right answer for a given sentence. Our objective is to be good at figuring out the output labels for sentences the system hasn't seen before.

Traditionally, the training data used in relation-extraction systems is a set of manually-annotated mention pairs in sentences. For example, to produce training data for the problem of extracting the Alma_Mater(person, university) relation from text, human annotators may label the following mentions pairs as positive examples of that relation: the mentions ("Bill Clinton," "Yale University") in the sentence "Bill Clinton was a student at Yale University;" the mentions ("Bill Gates," "Harvard") in the sentence "Bill Gates was a student at Harvard but dropped out."

# Feature Extraction

This training set will be used as input to the machine learning system, which aims to determine what patterns in the sentences containing the training mentions indicate the presence of certain relations. Since there can be many training examples, the system must determine a simple way to compare the relevant parts of sentence fragments involving mention pairs to each other. Creating this simplified representation of a mention pair in a sentence is called feature extraction. After performing feature extraction, each mention pair in a sentence is represented as a set of features that provide the system with a way to figure out which features correspond to which output labels.

Since we are performing relation extraction, and our target relation involves 2 entities, we need to perform entity linking to identify the entities corresponding to the mention pairs in the sentence, as described above. Now that we have the found the mentions for the entities, we can begin to extract features. A typical feature could be all the words that appear between the two entities (more complicated linguistic features such as dependency-path information could also be used). Recall that in our example we had the training set consisting of the mentions ("Bill Clinton," "Yale University") in the sentence "Bill Clinton was a student at Yale University;" the mentions ("Bill Gates," "Harvard") in the sentence "Bill Gates was a student at Harvard but dropped out" that were positive examples of the target relation Alma_Mater(person, university). With the feature we just defined (all the words appearing between the mention pair), the feature "was a student at" will be extracted for both training examples. Since both examples are positive, our system will determine, in the machine learning step, that the presence of "was a student at" between a person entity and a university entity is indicative of the mention pair being a positive instance of the target relation Alma_Mater.

# Extracting relations from new sentences

Ultimately, given a new, unseen sentence, and our target relation, we want to identify the entities in that sentence that participate in the relation. To do this we need to perform entity linking and then feature extraction on the mention pairs in the new sentence, and compare those features with the features that our system "learned" from the training examples in the machine learning step. If the new mention pair in the sentence contains features that are strong indicators of the target relation, then the new sentence contains a mention pair that is a positive instance of the relation. For example, if (given the same target relation as before) our new sentence is "Bill Clinton was a student at Yale University," we will extract the feature "was a student at", check that it matches the feature that our system knows is a strong indicator of positive instances, and output the relation Alma_Mater(Bill_Clinton, Yale_University).